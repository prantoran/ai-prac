{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNx9YZmhWKWm9m0lM1MStR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prantoran/ai-prac/blob/master/LLM-ZoomCamp-2025/hw_agents_mcp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework: Agents\n"
      ],
      "metadata": {
        "id": "41VGynMLeWdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this homework, we will learn more about function calling, and we will also explore MCP - model-context protocol."
      ],
      "metadata": {
        "id": "j5_Fz0XUeZVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "tzJmqf78ebcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll define a function that we will use when building our agent.\n",
        "\n",
        "It will generate fake weather data:"
      ],
      "metadata": {
        "id": "6gSY2lKYedmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "known_weather_data = {\n",
        "    'vancouver': 20.0\n",
        "}\n",
        "\n",
        "def get_weather(city: str) -> float:\n",
        "    print(f\"get_weather() called with city: {city}\")\n",
        "    city = city.strip().lower()\n",
        "\n",
        "    if city in known_weather_data:\n",
        "        print(f\"Returning known weather data for {city}\")\n",
        "        return known_weather_data[city]\n",
        "\n",
        "    print(f\"Returning random weather data for {city}\")\n",
        "    return round(random.uniform(-5, 35), 1)"
      ],
      "metadata": {
        "id": "MzzdcndweYN4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. Define function description"
      ],
      "metadata": {
        "id": "hr0NLJOtfB-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to use it as a tool for our agent, so we need to describe it\n",
        "\n",
        "How should the description for this function look like? Fill in missing parts"
      ],
      "metadata": {
        "id": "9lG8F21BffDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "get_weather_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"<TODO1>\",\n",
        "    \"description\": \"<TODO2>\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"<TODO3>\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"<TODO4>\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [TODO5],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "DxQJAHrCfgon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What did you put in TODO3?"
      ],
      "metadata": {
        "id": "8ukEDxqBfkWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"get_weather\",\n",
        "    \"description\": \"get_weather info\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"city\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"city name\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"city\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "iZpGf2iAelJI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing it (Optional)"
      ],
      "metadata": {
        "id": "Tv9iE2MwgA9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have OpenAI API Key (or alternative provider), let's test it.\n",
        "\n",
        "A question could be \"What's the weather like in Vancouver?\"\n",
        "\n",
        "Experiment with different system prompts to have better answers from the system."
      ],
      "metadata": {
        "id": "CEKOK18BgDhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You can use [chat_assistant.py](https://github.com/alexeygrigorev/rag-agents-workshop/blob/main/chat_assistant.py)\n",
        "or implement everything yourself"
      ],
      "metadata": {
        "id": "o6lDmlLlg18X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOrm1ousgBnX",
        "outputId": "cbc6c187-23ca-4934-cb16-ef48c92ff893"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-19 21:57:44--  https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3485 (3.4K) [text/plain]\n",
            "Saving to: â€˜chat_assistant.py.1â€™\n",
            "\n",
            "\rchat_assistant.py.1   0%[                    ]       0  --.-KB/s               \rchat_assistant.py.1 100%[===================>]   3.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-07-19 21:57:44 (38.4 MB/s) - â€˜chat_assistant.py.1â€™ saved [3485/3485]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from chat_assistant import ChatAssistant, Tools, ChatInterface"
      ],
      "metadata": {
        "id": "9Wi4w1Mag39Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = Tools()"
      ],
      "metadata": {
        "id": "qk1JY3-nqA-z"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools.add_tool(get_weather, get_weather_tool)"
      ],
      "metadata": {
        "id": "QTJuNtRbqFii"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools.get_tools()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRpCvW5mqYg4",
        "outputId": "0c0d9dd2-6806-4ba9-a55d-029f3cacb9f7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'name': 'get_weather',\n",
              "  'description': 'get_weather info',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'city': {'type': 'string', 'description': 'city name'}},\n",
              "   'required': ['city'],\n",
              "   'additionalProperties': False}}]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_interface = ChatInterface()"
      ],
      "metadata": {
        "id": "t7oG_eYAqdtc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "developer_prompt = \"You are weather reporter who is informing weather info to users. You can pick the right rools using the fnction decription to make function calls to answer the question.\""
      ],
      "metadata": {
        "id": "bOZwr3BdqnHL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW23RAZrrEvJ",
        "outputId": "e1c1c3ef-1de7-4544-889d-966b175e80a7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.96.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "0iejBFT6rP4x"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "wfvo185BrZjG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ChatAssistant(tools, developer_prompt, chat_interface, client)"
      ],
      "metadata": {
        "id": "_2RNuKZNpixH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "-JAmJuwZpycT",
        "outputId": "0b1b6b72-5644-4568-91a3-6f5c77e99c55"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:what is the weather in vancouver?\n",
            "tools::function_call() function_name: get_weather arguments: {'city': 'Vancouver'}\n",
            "get_weather() called with city: Vancouver\n",
            "Returning known weather data for vancouver\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <details>\n",
              "            <summary>Function call: <tt>get_weather({\"city\":\"Vancouver\"})</tt></summary>\n",
              "            <div>\n",
              "                <b>Call</b>\n",
              "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Vancouver\"}', call_id='call_eYMjqpuOTwESm2L8IArQPJao', name='get_weather', type='function_call', id='fc_687c14ecbb58819b95c9891904980f5605b7afc562cf2c28', status='completed')</pre>\n",
              "            </div>\n",
              "            <div>\n",
              "                <b>Output</b>\n",
              "                <pre>20.0</pre>\n",
              "            </div>\n",
              "            \n",
              "            </details>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>The current temperature in Vancouver is 20Â°C. If you need more detailed weather information, feel free to ask!</p></div>\n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:exit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>If you have any more questions in the future, feel free to ask. Have a great day! Goodbye!</p></div>\n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:stop\n",
            "Chat ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Adding another tool"
      ],
      "metadata": {
        "id": "I-qkh_xAs3N2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add another tool - a function that can add weather data to our database:"
      ],
      "metadata": {
        "id": "qkiY7c04s5TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_weather(city: str, temp: float) -> None:\n",
        "    print(f\"set_weather() called with city: {city}, temp: {temp}\")\n",
        "    city = city.strip().lower()\n",
        "    known_weather_data[city] = temp\n",
        "    return 'OK'"
      ],
      "metadata": {
        "id": "3zaK63pGrn2a"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write a description for it.\n",
        "\n",
        "What did you write?\n",
        "\n",
        "Optionally, you can test it after adding this function."
      ],
      "metadata": {
        "id": "zt0ux5h_tLki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_weather_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"set_weather\",\n",
        "    \"description\": \"set_weather info\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"city\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"city name\"\n",
        "            },\n",
        "            \"temp\": {\n",
        "                \"type\": \"number\",\n",
        "                \"description\": \"temperature in celcius\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"city\", \"temp\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "zQggyV82s-Oj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set_weather_tool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub3WX5yutiBA",
        "outputId": "89dee8cd-4e8f-46f3-81bb-b03dc8b9720e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type': 'function', 'name': 'set_weather', 'description': 'set_weather info', 'parameters': {'type': 'object', 'properties': {'city': {'type': 'string', 'description': 'city name'}, 'temp': {'type': 'number', 'description': 'temperature in celcius'}}, 'required': ['city', 'temp'], 'additionalProperties': False}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools.add_tool(set_weather, set_weather_tool)"
      ],
      "metadata": {
        "id": "ki1N34l1toYs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools.get_tools()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtuO1xabt1mt",
        "outputId": "6c3398c1-8084-4682-c564-e3002174f5e8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'name': 'get_weather',\n",
              "  'description': 'get_weather info',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'city': {'type': 'string', 'description': 'city name'}},\n",
              "   'required': ['city'],\n",
              "   'additionalProperties': False}},\n",
              " {'type': 'function',\n",
              "  'name': 'set_weather',\n",
              "  'description': 'set_weather info',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'city': {'type': 'string', 'description': 'city name'},\n",
              "    'temp': {'type': 'number', 'description': 'temperature in celcius'}},\n",
              "   'required': ['city', 'temp'],\n",
              "   'additionalProperties': False}}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ChatAssistant(tools, developer_prompt, chat_interface, client)\n",
        "agent.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ZsKs0yQdt3dW",
        "outputId": "6583fb03-4e70-42be-df37-e4d24baea934"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:set Dhaka's weather to 40 degree celcius\n",
            "tools::function_call() function_name: set_weather arguments: {'city': 'Dhaka', 'temp': 40}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <details>\n",
              "            <summary>Function call: <tt>set_weather({\"city\":\"Dhaka\",\"temp\":40})</tt></summary>\n",
              "            <div>\n",
              "                <b>Call</b>\n",
              "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Dhaka\",\"temp\":40}', call_id='call_WhI4TQlvSdJIdMU1yMoCOnTq', name='set_weather', type='function_call', id='fc_687c174763b88199ac76f764bf0c3f6d004e168a54f05d4b', status='completed')</pre>\n",
              "            </div>\n",
              "            <div>\n",
              "                <b>Output</b>\n",
              "                <pre>\"OK\"</pre>\n",
              "            </div>\n",
              "            \n",
              "            </details>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>The weather in Dhaka has been set to 40 degrees Celsius.</p></div>\n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:what is the weather in Dhaka\n",
            "tools::function_call() function_name: get_weather arguments: {'city': 'Dhaka'}\n",
            "get_weather() called with city: Dhaka\n",
            "Returning known weather data for dhaka\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <details>\n",
              "            <summary>Function call: <tt>get_weather({\"city\":\"Dhaka\"})</tt></summary>\n",
              "            <div>\n",
              "                <b>Call</b>\n",
              "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Dhaka\"}', call_id='call_b3OsqmDzhLGkkOdPz58eKc7d', name='get_weather', type='function_call', id='fc_687c1750e4b081998c105e3e152cb775004e168a54f05d4b', status='completed')</pre>\n",
              "            </div>\n",
              "            <div>\n",
              "                <b>Output</b>\n",
              "                <pre>40</pre>\n",
              "            </div>\n",
              "            \n",
              "            </details>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>The current weather in Dhaka is 40 degrees Celsius.</p></div>\n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:stop\n",
            "Chat ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MCP"
      ],
      "metadata": {
        "id": "AbRPUdhJvHy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCP stands for Model-Context Protocol. It allows LLMs communicate with different tools (like Qdrant). It's function calling, but one step further:\n",
        "\n",
        "- A tool can export a list of functions it has\n",
        "- When we include the tool to our Agent, we just need to include the link to the MCP server\n"
      ],
      "metadata": {
        "id": "WSYi96UcvNKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. Install FastMCP"
      ],
      "metadata": {
        "id": "4QFHVai_vxGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install a library for MCP - [FastMCP](https://github.com/jlowin/fastmcp):"
      ],
      "metadata": {
        "id": "HCRkKmv7v2eh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the version of FastMCP you installed?"
      ],
      "metadata": {
        "id": "CnSG0dgHxqOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastmcp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtvZQhmMt6nt",
        "outputId": "4c6a1000-dc06-4ac9-8859-3ce6c45f1ff7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastmcp\n",
            "  Downloading fastmcp-2.10.6-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting authlib>=1.5.2 (from fastmcp)\n",
            "  Downloading authlib-1.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting cyclopts>=3.0.0 (from fastmcp)\n",
            "  Downloading cyclopts-3.22.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting exceptiongroup>=1.2.2 (from fastmcp)\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from fastmcp) (0.28.1)\n",
            "Collecting mcp>=1.10.0 (from fastmcp)\n",
            "  Downloading mcp-1.12.0-py3-none-any.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openapi-pydantic>=0.5.1 (from fastmcp)\n",
            "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.11/dist-packages (from pydantic[email]>=2.11.7->fastmcp) (2.11.7)\n",
            "Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from fastmcp) (1.9.0)\n",
            "Collecting python-dotenv>=1.1.0 (from fastmcp)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from fastmcp) (13.9.4)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib>=1.5.2->fastmcp) (43.0.3)\n",
            "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.11/dist-packages (from cyclopts>=3.0.0->fastmcp) (25.3.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from cyclopts>=3.0.0->fastmcp) (0.16)\n",
            "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp)\n",
            "  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from exceptiongroup>=1.2.2->fastmcp) (4.14.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->fastmcp) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->fastmcp) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->fastmcp) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->fastmcp) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp) (0.16.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp>=1.10.0->fastmcp)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.10.0->fastmcp) (4.24.0)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp>=1.10.0->fastmcp)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.10.0->fastmcp) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp>=1.10.0->fastmcp)\n",
            "  Downloading sse_starlette-2.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.10.0->fastmcp) (0.47.1)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.10.0->fastmcp) (0.35.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.7->pydantic[email]>=2.11.7->fastmcp) (0.4.1)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->fastmcp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->fastmcp) (2.19.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->fastmcp) (1.3.1)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.10.0->fastmcp) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.10.0->fastmcp) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp>=1.10.0->fastmcp) (0.26.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp) (0.1.2)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.11/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp) (0.21.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp>=1.10.0->fastmcp) (8.2.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib>=1.5.2->fastmcp) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib>=1.5.2->fastmcp) (2.22)\n",
            "Downloading fastmcp-2.10.6-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading authlib-1.6.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cyclopts-3.22.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading mcp-1.12.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n",
            "Downloading sse_starlette-2.4.1-py3-none-any.whl (10 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, httpx-sse, exceptiongroup, dnspython, sse-starlette, email-validator, rich-rst, pydantic-settings, openapi-pydantic, authlib, mcp, cyclopts, fastmcp\n",
            "Successfully installed authlib-1.6.0 cyclopts-3.22.2 dnspython-2.7.0 email-validator-2.2.0 exceptiongroup-1.3.0 fastmcp-2.10.6 httpx-sse-0.4.1 mcp-1.12.0 openapi-pydantic-0.5.1 pydantic-settings-2.10.1 python-dotenv-1.1.1 rich-rst-1.3.1 sse-starlette-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. Simple MCP Server"
      ],
      "metadata": {
        "id": "QvqBCRpoxpRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple MCP server from the documentation looks like that:"
      ],
      "metadata": {
        "id": "hCnMsaQx1DCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# weather_server.py\n",
        "from fastmcp import FastMCP\n",
        "\n",
        "mcp = FastMCP(\"Demo ðŸš€\")\n",
        "\n",
        "@mcp.tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers\"\"\"\n",
        "    return a + b\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mcp.run()\n",
        "```"
      ],
      "metadata": {
        "id": "SuE0tOf21JGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our case, we need to write docstrings for our functions.\n",
        "\n",
        "Let's ask ChatGPT for help:\n",
        "\n"
      ],
      "metadata": {
        "id": "M1FeGX5G1TfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weather(city: str) -> float:\n",
        "    \"\"\"\n",
        "    Retrieves the temperature for a specified city.\n",
        "\n",
        "    Parameters:\n",
        "        city (str): The name of the city for which to retrieve weather data.\n",
        "\n",
        "    Returns:\n",
        "        float: The temperature associated with the city.\n",
        "    \"\"\"\n",
        "    city = city.strip().lower()\n",
        "\n",
        "    if city in known_weather_data:\n",
        "        return known_weather_data[city]\n",
        "\n",
        "    return round(random.uniform(-5, 35), 1)\n",
        "\n",
        "\n",
        "def set_weather(city: str, temp: float) -> None:\n",
        "    \"\"\"\n",
        "    Sets the temperature for a specified city.\n",
        "\n",
        "    Parameters:\n",
        "        city (str): The name of the city for which to set the weather data.\n",
        "        temp (float): The temperature to associate with the city.\n",
        "\n",
        "    Returns:\n",
        "        str: A confirmation string 'OK' indicating successful update.\n",
        "    \"\"\"\n",
        "    city = city.strip().lower()\n",
        "    known_weather_data[city] = temp\n",
        "    return 'OK'"
      ],
      "metadata": {
        "id": "MnfLgtRV1EL3"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's change the example for our case and run it\n",
        "\n",
        "What do you see in the output?\n",
        "\n",
        "Look for a string that matches this template:\n",
        "\n",
        "```\n",
        "Starting MCP server 'Demo ðŸš€' with transport '<TODO>'\n",
        "```\n",
        "\n",
        "What do you have instead of `<TODO>`?"
      ],
      "metadata": {
        "id": "pNR8EAF91j6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. Protocol"
      ],
      "metadata": {
        "id": "YnxFsl0K31jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "trABbra-BJOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LMO4b8fG96Lx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are different ways to communicate with an MCP server. Ours is currently running using standart input/output, which means that the client write something to stdin and read the answer using stdout.\n",
        "\n",
        "Our weather server is currently running.\n",
        "\n",
        "This is how we start communitcating with it:\n",
        "\n",
        "- First, we send an initialization request -- this way, we register our client with the server:\n",
        "    ```json\n",
        "    {\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {\"roots\": {\"listChanged\": true}, \"sampling\": {}}, \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}}}\n",
        "    ```\n",
        "    We should get back something like that, which is an aknowledgement of the request:\n",
        "    ```json\n",
        "    {\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"protocolVersion\":\"2024-11-05\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":false},\"resources\":{\"subscribe\":false,\"listChanged\":false},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"Demo ðŸš€\",\"version\":\"1.9.4\"}}}\n",
        "    ```\n",
        "-  Next, we reply back, confirming the initialization:\n",
        "    ```json\n",
        "    {\"jsonrpc\": \"2.0\", \"method\": \"notifications/initialized\"}\n",
        "    ```\n",
        "    We don't expect to get anything in response\n",
        "- Now we can ask for a list of available methods:\n",
        "    ```json\n",
        "    {\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/list\"}\n",
        "    ```\n",
        "- Let's ask the temperature in Berlin:\n",
        "    ```json\n",
        "    {\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"<TODO>\", \"arguments\": {<TODO>}}}\n",
        "    ```\n",
        "- What did you get in response?\n"
      ],
      "metadata": {
        "id": "yeVLHM8e4bVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```json\n",
        "{\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"get_weather\", \"arguments\": {\"city\": \"berlin\"}}}\n",
        "```"
      ],
      "metadata": {
        "id": "8M6pP0gg7NEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# weather_server.py\n",
        "from fastmcp import FastMCP\n",
        "import random\n",
        "\n",
        "known_weather_data = {\n",
        "    'berlin': 20.0,\n",
        "    'vancouver': 15.5,\n",
        "    'dhaka': 30.0,\n",
        "}\n",
        "\n",
        "mcp = FastMCP(\"Demo ðŸš€\")\n",
        "\n",
        "@mcp.tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@mcp.tool\n",
        "def get_weather(city: str) -> float:\n",
        "    \"\"\"\n",
        "    Retrieves the temperature for a specified city.\n",
        "\n",
        "    Parameters:\n",
        "        city (str): The name of the city for which to retrieve weather data.\n",
        "\n",
        "    Returns:\n",
        "        float: The temperature associated with the city.\n",
        "    \"\"\"\n",
        "    city = city.strip().lower()\n",
        "\n",
        "    if city in known_weather_data:\n",
        "        return known_weather_data[city]\n",
        "\n",
        "    return round(random.uniform(-5, 35), 1)\n",
        "\n",
        "@mcp.tool\n",
        "def set_weather(city: str, temp: float) -> None:\n",
        "    \"\"\"\n",
        "    Sets the temperature for a specified city.\n",
        "\n",
        "    Parameters:\n",
        "        city (str): The name of the city for which to set the weather data.\n",
        "        temp (float): The temperature to associate with the city.\n",
        "\n",
        "    Returns:\n",
        "        str: A confirmation string 'OK' indicating successful update.\n",
        "    \"\"\"\n",
        "    city = city.strip().lower()\n",
        "    known_weather_data[city] = temp\n",
        "    return 'OK'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mcp.run()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "1r3dIqLU97Vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. Client"
      ],
      "metadata": {
        "id": "bAxONknj765E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We typically don't interact with the server by copy-pasting commands in the terminal.\n",
        "\n",
        "In practice, we use an MCP Client. Let's implement it.\n",
        "\n",
        "FastMCP also supports MCP clients:\n",
        "\n",
        "```python\n",
        "from fastmcp import Client\n",
        "\n",
        "async def main():\n",
        "    async with Client(<TODO>) as mcp_client:\n",
        "        # TODO\n",
        "```\n",
        "\n",
        "Use the client to get the list of available tools\n",
        "of our script. How does the result look like?\n",
        "\n",
        "If you're running this code in Jupyter, you need to pass\n",
        "an instance of MCP server to the `Client`:\n",
        "\n",
        "```python\n",
        "import weather_server\n",
        "\n",
        "async def main():\n",
        "    async with Client(weather_server.mcp) as mcp_client:\n",
        "        # ....\n",
        "```\n",
        "\n",
        "If you run it in a script, you will need to use asyncio:\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    async with Client(\"weather_server.py\") as mcp_client:\n",
        "        # ...\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test = asyncio.run(main())\n",
        "```\n",
        "\n",
        "Copy the output with the available tools when\n",
        "filling in the homework form.\n"
      ],
      "metadata": {
        "id": "3oJR0IMX8AdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# raw_mcp_client.py\n",
        "\n",
        "import asyncio\n",
        "from fastmcp import Client\n",
        "\n",
        "async def main():\n",
        "    async with Client(\"weather_server.py\") as mcp_client:\n",
        "        print(await mcp_client.list_tools())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test = asyncio.run(main())\n",
        "```"
      ],
      "metadata": {
        "id": "ajFoUFOL9lwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using tools from the MCP server (optional)"
      ],
      "metadata": {
        "id": "8mei5bOX-UN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastMCP uses asyncio for client-server communication. In our\n",
        "case, the code we wrote previously in the module\n",
        "(chat_assistant.py) is not asyncio-friendly, so it will\n",
        "require a lot of adjustments to run it.\n",
        "\n",
        "Which is why we asked Claude to implement a simple\n",
        "non-async MCP client (see [mcp_client.py](mcp_client.py))\n",
        "that can only do this:\n",
        "\n",
        "- List tools\n",
        "- Invoke the specified tool\n",
        "\n",
        "Note: this is not a production-ready MCP Client! Use it\n",
        "only for learning purposes.\n",
        "\n",
        "Check the code - it's quite illustrative. Or experiment\n",
        "with writing this code yourself.\n",
        "\n",
        "Here's how we can use it:\n",
        "\n",
        "```python\n",
        "import mcp_client\n",
        "\n",
        "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
        "\n",
        "our_mcp_client.start_server()\n",
        "our_mcp_client.initialize()\n",
        "our_mcp_client.initialized()\n",
        "```\n",
        "\n",
        "While it's somewhat verbose, it follows\n",
        "the initialization structure we outlined in Q5.\n",
        "\n",
        "Now we can use it:\n",
        "\n",
        "```python\n",
        "our_mcp_client.get_tools()\n",
        "our_mcp_client.call_tool('get_weather', {'city': 'Berlin'})\n",
        "```\n",
        "\n",
        "In order to include it in our existing application, we need\n",
        "a wrapper class:\n",
        "\n",
        "```python\n",
        "import json\n",
        "\n",
        "class MCPTools:\n",
        "    def __init__(self, mcp_client):\n",
        "        self.mcp_client = mcp_client\n",
        "        self.tools = None\n",
        "    \n",
        "    def get_tools(self):\n",
        "        if self.tools is None:\n",
        "            mcp_tools = self.mcp_client.get_tools()\n",
        "            self.tools = convert_tools_list(mcp_tools)\n",
        "        return self.tools\n",
        "\n",
        "    def function_call(self, tool_call_response):\n",
        "        function_name = tool_call_response.name\n",
        "        arguments = json.loads(tool_call_response.arguments)\n",
        "\n",
        "        result = self.mcp_client.call_tool(function_name, arguments)\n",
        "\n",
        "        return {\n",
        "            \"type\": \"function_call_output\",\n",
        "            \"call_id\": tool_call_response.call_id,\n",
        "            \"output\": json.dumps(result, indent=2),\n",
        "        }\n",
        "```\n",
        "\n",
        "It's very similar to the `Tools` class we created in the\n",
        "module, but it uses MCP to communicate with the MCP Server.\n",
        "\n",
        "(Where `convert_tools_list` converts MCP functions description\n",
        "format into the OpenAI's one)\n",
        "\n",
        "Let's use it:\n",
        "\n",
        "```python\n",
        "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
        "\n",
        "our_mcp_client.start_server()\n",
        "our_mcp_client.initialize()\n",
        "our_mcp_client.initialized()\n",
        "\n",
        "mcp_tools = mcp_client.MCPTools(mcp_client=our_mcp_client)\n",
        "\n",
        "\n",
        "developer_prompt = \"\"\"\n",
        "You help users find out the weather in their cities.\n",
        "If they didn't specify a city, ask them. Make sure we always use a city.\n",
        "\"\"\".strip()\n",
        "\n",
        "chat_interface = chat_assistant.ChatInterface()\n",
        "\n",
        "chat = chat_assistant.ChatAssistant(\n",
        "    tools=mcp_tools,\n",
        "    developer_prompt=developer_prompt,\n",
        "    chat_interface=chat_interface,\n",
        "    client=client\n",
        ")\n",
        "\n",
        "chat.run()\n",
        "```\n",
        "\n",
        "Now we use the MCP server for function calling!\n"
      ],
      "metadata": {
        "id": "Hxk6Vf85-ass"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/cohorts/2025/0a-agents/mcp_client.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVSe3k8q4Wbv",
        "outputId": "0a60faa8-403e-4edd-bf17-dc6900cb46fa"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-19 23:23:41--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/cohorts/2025/0a-agents/mcp_client.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9117 (8.9K) [text/plain]\n",
            "Saving to: â€˜mcp_client.pyâ€™\n",
            "\n",
            "\rmcp_client.py         0%[                    ]       0  --.-KB/s               \rmcp_client.py       100%[===================>]   8.90K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-07-19 23:23:41 (36.9 MB/s) - â€˜mcp_client.pyâ€™ saved [9117/9117]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mcp_client\n",
        "\n",
        "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
        "\n",
        "our_mcp_client.start_server()\n",
        "our_mcp_client.initialize()\n",
        "our_mcp_client.initialized()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vTgHMxg_rty",
        "outputId": "5b62534b-4f05-49bf-ffb8-d4246c4d93ec"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started server with command: python weather_server.py\n",
            "Sending initialize request...\n",
            "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo ðŸš€', 'version': '1.12.0'}}\n",
            "Sending initialized notification...\n",
            "Handshake completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "our_mcp_client.get_tools()\n",
        "our_mcp_client.call_tool('get_weather', {'city': 'Berlin'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxjnrb8a_0KO",
        "outputId": "77a7db2c-8569-4ddd-fdba-59c434e333a9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving available tools...\n",
            "Available tools: ['add', 'get_weather', 'set_weather']\n",
            "Calling tool 'get_weather' with arguments: {'city': 'Berlin'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'content': [{'type': 'text', 'text': '20.0'}],\n",
              " 'structuredContent': {'result': 20.0},\n",
              " 'isError': False}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
        "\n",
        "our_mcp_client.start_server()\n",
        "our_mcp_client.initialize()\n",
        "our_mcp_client.initialized()\n",
        "\n",
        "mcp_tools = mcp_client.MCPTools(mcp_client=our_mcp_client)\n",
        "\n",
        "\n",
        "developer_prompt = \"\"\"\n",
        "You help users find out the weather in their cities.\n",
        "If they didn't specify a city, ask them. Make sure we always use a city.\n",
        "\"\"\".strip()\n",
        "\n",
        "chat_interface = ChatInterface()\n",
        "\n",
        "chat = ChatAssistant(\n",
        "    tools=mcp_tools,\n",
        "    developer_prompt=developer_prompt,\n",
        "    chat_interface=chat_interface,\n",
        "    client=client\n",
        ")\n",
        "\n",
        "chat.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "Fy4eutpjAjFX",
        "outputId": "f52e4332-6326-497c-8354-23097f3e3767"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started server with command: python weather_server.py\n",
            "Sending initialize request...\n",
            "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Demo ðŸš€', 'version': '1.12.0'}}\n",
            "Sending initialized notification...\n",
            "Handshake completed successfully\n",
            "You:what is the weather in berlin\n",
            "Retrieving available tools...\n",
            "Available tools: ['add', 'get_weather', 'set_weather']\n",
            "Calling tool 'get_weather' with arguments: {'city': 'berlin'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <details>\n",
              "            <summary>Function call: <tt>get_weather({\"city\":\"berlin\"})</tt></summary>\n",
              "            <div>\n",
              "                <b>Call</b>\n",
              "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"berlin\"}', call_id='call_RgP5NOQJhWIYrhwJdel8LGxm', name='get_weather', type='function_call', id='fc_687c2a0ba2588199b2d4d55d0c0f86460f3779dbae00e816', status='completed')</pre>\n",
              "            </div>\n",
              "            <div>\n",
              "                <b>Output</b>\n",
              "                <pre>{\n",
              "  \"content\": [\n",
              "    {\n",
              "      \"type\": \"text\",\n",
              "      \"text\": \"20.0\"\n",
              "    }\n",
              "  ],\n",
              "  \"structuredContent\": {\n",
              "    \"result\": 20.0\n",
              "  },\n",
              "  \"isError\": false\n",
              "}</pre>\n",
              "            </div>\n",
              "            \n",
              "            </details>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>The current temperature in Berlin is 20Â°C.</p></div>\n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:stop\n",
            "Chat ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "drPaidjDA8SJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}