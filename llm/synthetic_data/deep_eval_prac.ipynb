{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMhmxXKtkNyCJUORj8b1v/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prantoran/ai-prac/blob/master/llm/synthetic_data/deep_eval_prac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfATkaPdrG6n",
        "outputId": "821def67-edaf-4a61-d59a-c5bd057327ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Collecting langchain-core<0.4.0,>=0.3.32 (from langchain)\n",
            "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.59.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.32\n",
            "    Uninstalling langchain-core-0.3.32:\n",
            "      Successfully uninstalled langchain-core-0.3.32\n",
            "Successfully installed langchain-core-0.3.33 langchain_openai-0.3.3 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrwiQKZkr8Db",
        "outputId": "16be5e26-dff8-4a9f-c46d-b7e6a46cb762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.16)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.16 marshmallow-3.26.0 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_text_splitters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PV5Z0uHsC4r",
        "outputId": "edb9d02e-80cf-4f59-e424-cdf6912762f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain_text_splitters) (0.3.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (2.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain_text_splitters) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tiktoken -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3v-W-TRsUtu",
        "outputId": "5739e6e2-50a9-459e-b4ae-68760c400dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk7T5MJ5saBx",
        "outputId": "5fed15e1-ec59-4e41-e13d-20fe4ade0f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.2.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.2.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUDAGdUes870",
        "outputId": "d32f9cfb-5379-445f-ee2d-0154da26e9e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/ToRead/RLSyllabus.pdf"
      ],
      "metadata": {
        "id": "yQtScjG8thqi",
        "outputId": "2e08bb29-e21f-4000-bd90-a447b6555945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/ToRead/RLSyllabus.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = '...'"
      ],
      "metadata": {
        "id": "Zz02n2Wp7Qx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Chunking"
      ],
      "metadata": {
        "id": "ENogXUfnve9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create chunks"
      ],
      "metadata": {
        "id": "I0AWhEH7uylT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1. Chunk Documents\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import TokenTextSplitter\n",
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "text_splitter = TokenTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
        "\n",
        "loader = PyPDFLoader(\"drive/MyDrive/ToRead/RLSyllabus.pdf\")\n",
        "raw_chunks = loader.load_and_split(text_splitter)\n"
      ],
      "metadata": {
        "id": "TN63_HmHrMii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c175bc2-9e16-4319-ac1c-a85d138f8a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert chunks to embeddings"
      ],
      "metadata": {
        "id": "5hLfcOl1u0yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "LhozubUZvL6a",
        "outputId": "67412ae1-8335-40e8-803b-fb07da41a48b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.33)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.59.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_openai) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_openai) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(api_key=OPEN_API_KEY)\n",
        "content = [rc.page_content for rc in raw_chunks]\n",
        "embeddings = embedding_model.embed_documents(content)\n"
      ],
      "metadata": {
        "id": "vWPWElmKsAmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohJsWDCMxkT3",
        "outputId": "01bddce2-b674-48a8-8da9-9cce7b8b8cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laeCnn1wxvde",
        "outputId": "33561d19-6495-4b75-e064-d162d4398c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiwDoewMxzbE",
        "outputId": "bee95a6b-5b34-4ce6-a624-a9737e4310ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z11oSmlZx6b0",
        "outputId": "496e0172-79d0-4c44-912a-50b77239dee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Generation"
      ],
      "metadata": {
        "id": "hDtoOqgyv_t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomly select a chunk as focal anchor"
      ],
      "metadata": {
        "id": "8cosYIQbw2JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Generate context by selecting chunks\n",
        "import random\n",
        "\n",
        "reference_index = random.randint(0, len(embeddings) - 1)\n",
        "reference_embedding = embeddings[reference_index]\n",
        "contexts = [content[reference_index]]\n",
        "print(\"Reference index: \" + str(reference_index), \"with contexts: \", contexts)\n"
      ],
      "metadata": {
        "id": "7pZ9oDgFr0iM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae8ba27-5c52-4c3e-f5c5-fdfc06861fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference index: 0 with contexts:  ['IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify related chunks"
      ],
      "metadata": {
        "id": "K92F4RXdye8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "similarity_threshold = 0.8\n",
        "similar_indices = []\n",
        "for i, embedding in enumerate(embeddings):\n",
        "    product = np.dot(reference_embedding, embedding)\n",
        "    norm = np.linalg.norm(reference_embedding) * np.linalg.norm(embedding)\n",
        "    similarity = product / norm\n",
        "    print(i, product, norm, similarity)\n",
        "    if similarity >= similarity_threshold:\n",
        "        similar_indices.append(i)\n",
        "\n",
        "for i in similar_indices:\n",
        "    contexts.append(content[i])\n",
        "print(len(contexts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJQH5SjXyGH5",
        "outputId": "1b0ffb01-83b8-4f6f-9472-28b6826e6931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.9999998433066166 0.9999998433066165 1.0000000000000002\n",
            "1 0.889226653766511 0.9999998753185456 0.8892267646365973\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query Generation"
      ],
      "metadata": {
        "id": "7g873NyZ2B5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide a prompt that asks the model to act as a copywriter, generating JSON objects containing an input key, which is the query. Each input should either be a question or statement answerable using the provided context."
      ],
      "metadata": {
        "id": "Ml_opzIY2NYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: the focal anchor chunk is included twice."
      ],
      "metadata": {
        "id": "lLW-bO8m0Pqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3. Generate a series of queries for similar chunks\n",
        "from langchain_openai import ChatOpenAI\n",
        "...\n",
        "\n",
        "prompt = f\"\"\"I want you act as a copywriter. Based on the given context,\n",
        "which is list of strings, please generate a list of JSON objects\n",
        "with a `input` key. The `input` can either be a question or a\n",
        "statement that can be addressed by the given context.\n",
        "\n",
        "contexts:\n",
        "{contexts}\"\"\"\n",
        "\n",
        "print(\"prompt:\\n\", prompt)\n",
        "\n",
        "query = ChatOpenAI(openai_api_key=OPEN_API_KEY).invoke(prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvvpVNI6zS7a",
        "outputId": "7c5df879-6d6d-40e8-cbe8-7871ae193fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt:\n",
            " I want you act as a copywriter. Based on the given context, \n",
            "which is list of strings, please generate a list of JSON objects \n",
            "with a `input` key. The `input` can either be a question or a \n",
            "statement that can be addressed by the given context.\n",
            "\n",
            "contexts:\n",
            "['IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'In the first two weeks, we will review the fundamentals of Reinforcement Learning at a fast pace. Below \\nis a tentative list of papers that we plan to read after that. More papers may be added as the class \\nproceeds. Students will be encouraged to suggest papers. \\nPapers on Deep RL algorithms \\n1. Approximately Optimal Approximate Reinforcement Learning,  Sham Kakade, John Langford \\n(2002) [THEORY] \\n2. Trust Region Policy Optimization, John Schulman, Sergey Levine, Philipp Moritz, Michael I. \\nJordan, Pieter Abbeel (2015)  [THEORY] \\n3. Proximal Policy Optimization Algorithms, John Schulman, Filip Wolski, Prafulla Dhariwal, Alec \\nRadford, Oleg Klimov (2017) \\n4. Playing Atari with Deep Reinforcement Learning, Volodymyr Mnih, Koray Kavukcuoglu, David \\nSilver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller. (2016) \\n5. Asynchronous Methods for Deep Reinforcement Learning, Volodymyr Mnih, Adrià \\nPuigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, \\nKoray Kavukcuoglu (2016) \\n6. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic \\nActor, Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine. (2018) \\n \\nPapers on RLHF \\n1. Deep reinforcement learning from human preferences, Paul Christiano, Jan Leike, Tom B. Brown, \\nMiljan Martic, Shane Legg, Dario Amodei, NeurIPS (2017) \\n2. Training language models to follow instructions with human feedback, L. Ouyang, J. Wu, X. Jiang, \\nD. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al,  NeurIPS \\n(2022) \\n3. Contextual dueling bandits. Dudik, M., Hofmann, K., Schapire, R. E., Slivkins, A. and Zoghi, M. \\n(2015).  In Conference on Learning Theory. [THEORY] \\n4. Preference-based reinforcement learning with finite-time guarantees. Yichong Xu, Ruosong \\nWang, Lin Yang, Aarti Singh, and Artur Dubrawski. NeurIPS (2020) [THEORY] \\n5. Dueling rl: reinforcement learning with trajectory preferences, A. Pacchiano, A. Saha, and J. Lee.  \\n(2021) [THEORY] \\n6. Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons, \\nBanghua Zhu, Michael I. Jordan, Jiantao Jiao, ICML  (2023) [THEORY] \\n7. Nash Learning from Human Feedback,  Munos et al., ICML (2024)  \\n8. Self-Play Preference Optimization for Language Model Alignment, Yue Wu, Zhiqing Sun, Huizhuo \\nYuan, Kaixuan Ji, Yiming Yang, Quanquan Gu, ICML (2024) \\n \\n \\n \\n \\n \\n \\n ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GQcz3g92pj7",
        "outputId": "3b718011-d678-4d36-ef0b-06994931e1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='[\\n    {\\n        \"input\": \"What are the prerequisites for IEOR 8100: Advanced topics in Reinforcement Learning?\"\\n    },\\n    {\\n        \"input\": \"Can students suggest papers to read in the course on Reinforcement Learning?\"\\n    },\\n    {\\n        \"input\": \"What is the course structure and requirements for IEOR 8100?\"\\n    },\\n    {\\n        \"input\": \"What are some important papers on deep reinforcement learning algorithms and analysis?\"\\n    },\\n    {\\n        \"input\": \"What is the focus of the course on reinforcement learning with human feedback (RLHF)?\"\\n    }\\n]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 2197, 'total_tokens': 2322, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-56025f3b-0e92-4a03-b092-b53115ad6405-0', usage_metadata={'input_tokens': 2197, 'output_tokens': 125, 'total_tokens': 2322, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query Evolution"
      ],
      "metadata": {
        "id": "Ac5whKtH303z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Templates"
      ],
      "metadata": {
        "id": "OMMf6uQm6Hce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying out multi-context understanding, multi-step reasoning, and hypothetical scenario. Other templates are also possible."
      ],
      "metadata": {
        "id": "6MB6_Hym39Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolution prompt templates as strings\n",
        "multi_context_template = \"\"\"\n",
        "I want you to rewrite the given `input` so that it requires readers to use information from all elements in `Context`.\n",
        "\n",
        "1. `Input` should require information from all `Context` elements.\n",
        "2. `Rewritten Input` must be concise and fully answerable from `Context`.\n",
        "3. Do not use phrases like 'based on the provided context.'\n",
        "4. `Rewritten Input` should not exceed 15 words.\n",
        "\n",
        "Context: {context}\n",
        "Input: {original_input}\n",
        "Rewritten Input:\n",
        "\"\"\"\n",
        "\n",
        "reasoning_template = \"\"\"\n",
        "I want you to rewrite the given `input` so that it explicitly requests multi-step reasoning.\n",
        "\n",
        "1. `Rewritten Input` should require multiple logical connections or inferences.\n",
        "2. `Rewritten Input` should be concise and understandable.\n",
        "3. Do not use phrases like 'based on the provided context.'\n",
        "4. `Rewritten Input` must be fully answerable from `Context`.\n",
        "5. `Rewritten Input` should not exceed 15 words.\n",
        "\n",
        "Context: {context}\n",
        "Input: {original_input}\n",
        "Rewritten Input:\n",
        "\"\"\"\n",
        "\n",
        "hypothetical_scenario_template = \"\"\"\n",
        "I want you to rewrite the given `input` to incorporate a hypothetical or speculative scenario.\n",
        "\n",
        "1. `Rewritten Input` should encourage applying knowledge from `Context` to deduce outcomes.\n",
        "2. `Rewritten Input` should be concise and understandable.\n",
        "3. Do not use phrases like 'based on the provided context.'\n",
        "4. `Rewritten Input` must be fully answerable from `Context`.\n",
        "5. `Rewritten Input` should not exceed 15 words.\n",
        "\n",
        "Context: {context}\n",
        "Input: {original_input}\n",
        "Rewritten Input:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "FZuJFzoo3be6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evolve Queries"
      ],
      "metadata": {
        "id": "AqrdYrS06Lj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4. Evolve Queries\n",
        "...\n",
        "\n",
        "example_generated_query = \"How do chatbots use natural language understanding?\"\n",
        "context = contexts\n",
        "original_input = example_generated_query\n",
        "evolution_templates = [multi_context_template, reasoning_template, hypothetical_scenario_template]\n",
        "\n",
        "print(\"original_input:\\n\", original_input)\n",
        "print(\"context:\\n\", context)\n",
        "print(\"example_generated_query:\\n\", example_generated_query)\n",
        "# Number of evolution steps to apply\n",
        "num_evolution_steps = 3\n",
        "\n",
        "# Function to perform random evolution steps\n",
        "def evolve_query(original_input, context, steps):\n",
        "    current_input = original_input\n",
        "    for _ in range(steps):\n",
        "        if type(current_input) is not str:\n",
        "          current_input = current_input.content\n",
        "        # Choose a random (or using custom logic) template from the list\n",
        "        chosen_template = random.choice(evolution_templates)\n",
        "        # Replace the placeholders with the current context and input\n",
        "        evolved_prompt = chosen_template.replace(\"{context}\", str(context))\n",
        "        evolved_prompt = evolved_prompt.replace(\"{original_input}\", current_input)\n",
        "        print(\"evolved_prompt:\\n\", evolved_prompt)\n",
        "        # Update the current input with the \"Rewritten Input\" section\n",
        "        current_input = ChatOpenAI(openai_api_key=OPEN_API_KEY).invoke(evolved_prompt)\n",
        "    return current_input\n",
        "\n",
        "# Evolve the input by randomly selecting the evolution type\n",
        "evolved_query = evolve_query(original_input, context, num_evolution_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fES2ok0s4Izl",
        "outputId": "161e264a-a5bf-4e21-aa59-27882ca4134c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original_input:\n",
            " How do chatbots use natural language understanding?\n",
            "context:\n",
            " ['IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'In the first two weeks, we will review the fundamentals of Reinforcement Learning at a fast pace. Below \\nis a tentative list of papers that we plan to read after that. More papers may be added as the class \\nproceeds. Students will be encouraged to suggest papers. \\nPapers on Deep RL algorithms \\n1. Approximately Optimal Approximate Reinforcement Learning,  Sham Kakade, John Langford \\n(2002) [THEORY] \\n2. Trust Region Policy Optimization, John Schulman, Sergey Levine, Philipp Moritz, Michael I. \\nJordan, Pieter Abbeel (2015)  [THEORY] \\n3. Proximal Policy Optimization Algorithms, John Schulman, Filip Wolski, Prafulla Dhariwal, Alec \\nRadford, Oleg Klimov (2017) \\n4. Playing Atari with Deep Reinforcement Learning, Volodymyr Mnih, Koray Kavukcuoglu, David \\nSilver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller. (2016) \\n5. Asynchronous Methods for Deep Reinforcement Learning, Volodymyr Mnih, Adrià \\nPuigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, \\nKoray Kavukcuoglu (2016) \\n6. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic \\nActor, Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine. (2018) \\n \\nPapers on RLHF \\n1. Deep reinforcement learning from human preferences, Paul Christiano, Jan Leike, Tom B. Brown, \\nMiljan Martic, Shane Legg, Dario Amodei, NeurIPS (2017) \\n2. Training language models to follow instructions with human feedback, L. Ouyang, J. Wu, X. Jiang, \\nD. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al,  NeurIPS \\n(2022) \\n3. Contextual dueling bandits. Dudik, M., Hofmann, K., Schapire, R. E., Slivkins, A. and Zoghi, M. \\n(2015).  In Conference on Learning Theory. [THEORY] \\n4. Preference-based reinforcement learning with finite-time guarantees. Yichong Xu, Ruosong \\nWang, Lin Yang, Aarti Singh, and Artur Dubrawski. NeurIPS (2020) [THEORY] \\n5. Dueling rl: reinforcement learning with trajectory preferences, A. Pacchiano, A. Saha, and J. Lee.  \\n(2021) [THEORY] \\n6. Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons, \\nBanghua Zhu, Michael I. Jordan, Jiantao Jiao, ICML  (2023) [THEORY] \\n7. Nash Learning from Human Feedback,  Munos et al., ICML (2024)  \\n8. Self-Play Preference Optimization for Language Model Alignment, Yue Wu, Zhiqing Sun, Huizhuo \\nYuan, Kaixuan Ji, Yiming Yang, Quanquan Gu, ICML (2024) \\n \\n \\n \\n \\n \\n \\n ']\n",
            "example_generated_query:\n",
            " How do chatbots use natural language understanding?\n",
            "evolved_prompt:\n",
            " \n",
            "I want you to rewrite the given `input` to incorporate a hypothetical or speculative scenario.\n",
            "\n",
            "1. `Rewritten Input` should encourage applying knowledge from `Context` to deduce outcomes.\n",
            "2. `Rewritten Input` should be concise and understandable.\n",
            "3. Do not use phrases like 'based on the provided context.'\n",
            "4. `Rewritten Input` must be fully answerable from `Context`.\n",
            "5. `Rewritten Input` should not exceed 15 words.\n",
            "\n",
            "Context: ['IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'In the first two weeks, we will review the fundamentals of Reinforcement Learning at a fast pace. Below \\nis a tentative list of papers that we plan to read after that. More papers may be added as the class \\nproceeds. Students will be encouraged to suggest papers. \\nPapers on Deep RL algorithms \\n1. Approximately Optimal Approximate Reinforcement Learning,  Sham Kakade, John Langford \\n(2002) [THEORY] \\n2. Trust Region Policy Optimization, John Schulman, Sergey Levine, Philipp Moritz, Michael I. \\nJordan, Pieter Abbeel (2015)  [THEORY] \\n3. Proximal Policy Optimization Algorithms, John Schulman, Filip Wolski, Prafulla Dhariwal, Alec \\nRadford, Oleg Klimov (2017) \\n4. Playing Atari with Deep Reinforcement Learning, Volodymyr Mnih, Koray Kavukcuoglu, David \\nSilver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller. (2016) \\n5. Asynchronous Methods for Deep Reinforcement Learning, Volodymyr Mnih, Adrià \\nPuigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, \\nKoray Kavukcuoglu (2016) \\n6. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic \\nActor, Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine. (2018) \\n \\nPapers on RLHF \\n1. Deep reinforcement learning from human preferences, Paul Christiano, Jan Leike, Tom B. Brown, \\nMiljan Martic, Shane Legg, Dario Amodei, NeurIPS (2017) \\n2. Training language models to follow instructions with human feedback, L. Ouyang, J. Wu, X. Jiang, \\nD. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al,  NeurIPS \\n(2022) \\n3. Contextual dueling bandits. Dudik, M., Hofmann, K., Schapire, R. E., Slivkins, A. and Zoghi, M. \\n(2015).  In Conference on Learning Theory. [THEORY] \\n4. Preference-based reinforcement learning with finite-time guarantees. Yichong Xu, Ruosong \\nWang, Lin Yang, Aarti Singh, and Artur Dubrawski. NeurIPS (2020) [THEORY] \\n5. Dueling rl: reinforcement learning with trajectory preferences, A. Pacchiano, A. Saha, and J. Lee.  \\n(2021) [THEORY] \\n6. Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons, \\nBanghua Zhu, Michael I. Jordan, Jiantao Jiao, ICML  (2023) [THEORY] \\n7. Nash Learning from Human Feedback,  Munos et al., ICML (2024)  \\n8. Self-Play Preference Optimization for Language Model Alignment, Yue Wu, Zhiqing Sun, Huizhuo \\nYuan, Kaixuan Ji, Yiming Yang, Quanquan Gu, ICML (2024) \\n \\n \\n \\n \\n \\n \\n ']\n",
            "Input: How do chatbots use natural language understanding?\n",
            "Rewritten Input:\n",
            "\n",
            "evolved_prompt:\n",
            " \n",
            "I want you to rewrite the given `input` to incorporate a hypothetical or speculative scenario.\n",
            "\n",
            "1. `Rewritten Input` should encourage applying knowledge from `Context` to deduce outcomes.\n",
            "2. `Rewritten Input` should be concise and understandable.\n",
            "3. Do not use phrases like 'based on the provided context.'\n",
            "4. `Rewritten Input` must be fully answerable from `Context`.\n",
            "5. `Rewritten Input` should not exceed 15 words.\n",
            "\n",
            "Context: ['IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'In the first two weeks, we will review the fundamentals of Reinforcement Learning at a fast pace. Below \\nis a tentative list of papers that we plan to read after that. More papers may be added as the class \\nproceeds. Students will be encouraged to suggest papers. \\nPapers on Deep RL algorithms \\n1. Approximately Optimal Approximate Reinforcement Learning,  Sham Kakade, John Langford \\n(2002) [THEORY] \\n2. Trust Region Policy Optimization, John Schulman, Sergey Levine, Philipp Moritz, Michael I. \\nJordan, Pieter Abbeel (2015)  [THEORY] \\n3. Proximal Policy Optimization Algorithms, John Schulman, Filip Wolski, Prafulla Dhariwal, Alec \\nRadford, Oleg Klimov (2017) \\n4. Playing Atari with Deep Reinforcement Learning, Volodymyr Mnih, Koray Kavukcuoglu, David \\nSilver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller. (2016) \\n5. Asynchronous Methods for Deep Reinforcement Learning, Volodymyr Mnih, Adrià \\nPuigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, \\nKoray Kavukcuoglu (2016) \\n6. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic \\nActor, Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine. (2018) \\n \\nPapers on RLHF \\n1. Deep reinforcement learning from human preferences, Paul Christiano, Jan Leike, Tom B. Brown, \\nMiljan Martic, Shane Legg, Dario Amodei, NeurIPS (2017) \\n2. Training language models to follow instructions with human feedback, L. Ouyang, J. Wu, X. Jiang, \\nD. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al,  NeurIPS \\n(2022) \\n3. Contextual dueling bandits. Dudik, M., Hofmann, K., Schapire, R. E., Slivkins, A. and Zoghi, M. \\n(2015).  In Conference on Learning Theory. [THEORY] \\n4. Preference-based reinforcement learning with finite-time guarantees. Yichong Xu, Ruosong \\nWang, Lin Yang, Aarti Singh, and Artur Dubrawski. NeurIPS (2020) [THEORY] \\n5. Dueling rl: reinforcement learning with trajectory preferences, A. Pacchiano, A. Saha, and J. Lee.  \\n(2021) [THEORY] \\n6. Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons, \\nBanghua Zhu, Michael I. Jordan, Jiantao Jiao, ICML  (2023) [THEORY] \\n7. Nash Learning from Human Feedback,  Munos et al., ICML (2024)  \\n8. Self-Play Preference Optimization for Language Model Alignment, Yue Wu, Zhiqing Sun, Huizhuo \\nYuan, Kaixuan Ji, Yiming Yang, Quanquan Gu, ICML (2024) \\n \\n \\n \\n \\n \\n \\n ']\n",
            "Input: Discuss the practical applications of natural language understanding in chatbot technology.\n",
            "Rewritten Input:\n",
            "\n",
            "evolved_prompt:\n",
            " \n",
            "I want you to rewrite the given `input` to incorporate a hypothetical or speculative scenario.\n",
            "\n",
            "1. `Rewritten Input` should encourage applying knowledge from `Context` to deduce outcomes.\n",
            "2. `Rewritten Input` should be concise and understandable.\n",
            "3. Do not use phrases like 'based on the provided context.'\n",
            "4. `Rewritten Input` must be fully answerable from `Context`.\n",
            "5. `Rewritten Input` should not exceed 15 words.\n",
            "\n",
            "Context: ['IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'IEOR 8100: Advanced topics in Reinforcement Learning \\nInstructor:  Shipra Agrawal \\nMeeting time: Mondays and Wednesdays, 11:40 am - 12:55 pm, Location TBD \\nIn this course, we will read recent research papers on reinforcement learning, with a particular emphasis \\non advancements on reinforcement learning from human feedback (RLHF). RLHF has been popularized \\nas a main method for aligning LLMs with human values and preferences. After a quick overview of basic \\nconcepts in reinforcement learning, we will read some important papers on deep reinforcement \\nlearning algorithms and analysis, followed by recent papers covering both empirical and theoretical \\nfoundations of RLHF. These will be interspersed papers on relevant topics such as dueling bandits, \\ninverse RL, imitation learning, multi-agent RL and offline RL, which form the technical basis of many \\nrecent directions in RLHF. \\nPrerequisites \\nThis course is mainly aimed at PhD students or advanced master’s students interested in research in RL. \\nAny student taking this course is expected to have experience (and interest) in reading and \\nunderstanding research papers. Students must also have some experience with machine learning \\n(preferably deep learning), and some familiarity with reinforcement learning, including the necessary \\nmathematical background (linear algebra and statistics) and the ability to implement ML/RL algorithms. \\nIf prior knowledge of reinforcement learning is insufficient, students are encouraged to take the course \\nORCS 4529 (Reinforcement Learning) instead, which is being taught in parallel to this class by the same \\ninstructor. PhD students with relevant backgrounds may audit ORCS 4529 in order to supplement their \\nunderstanding of RL. \\nCourse Structure and requirements \\nThis class is mainly a paper-reading seminar covering recent important papers on reinforcement learning \\nwith human feedback and related topics. Every student is also required to finish an open-ended final \\nresearch project. The project may be theoretical or empirical and may be conducted individually or in a \\ngroup of at most 3 students. Project proposal guidelines and report timelines will be discussed in the \\nfirst couple of weeks of the class. \\nNote that after the first two weeks of classes, students are not allowed to audit this course. If you have a \\nspecial circumstance, please talk to the instructor in advance. \\nReadings \\nFor much of the semester, each class will involve the presentation and discussion of one paper. Before \\neach class, everyone is required to have read the paper. In a given class session, students in the \\npresenting group will each be given a rotating role (Presenter, Reviewer, Archaeologist, Researcher, and \\nHacker, described in detail on the course page). This role defines the lens through which they read the \\npaper and determines what they prepare for the group in-class discussion. Students in the non-\\npresenting group are also required to read the paper, and come to class ready to discuss. All students \\nwill obtain a thorough understanding of the chosen papers and will develop their paper reading, \\nliterature review, and prototyping skills. ', 'In the first two weeks, we will review the fundamentals of Reinforcement Learning at a fast pace. Below \\nis a tentative list of papers that we plan to read after that. More papers may be added as the class \\nproceeds. Students will be encouraged to suggest papers. \\nPapers on Deep RL algorithms \\n1. Approximately Optimal Approximate Reinforcement Learning,  Sham Kakade, John Langford \\n(2002) [THEORY] \\n2. Trust Region Policy Optimization, John Schulman, Sergey Levine, Philipp Moritz, Michael I. \\nJordan, Pieter Abbeel (2015)  [THEORY] \\n3. Proximal Policy Optimization Algorithms, John Schulman, Filip Wolski, Prafulla Dhariwal, Alec \\nRadford, Oleg Klimov (2017) \\n4. Playing Atari with Deep Reinforcement Learning, Volodymyr Mnih, Koray Kavukcuoglu, David \\nSilver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller. (2016) \\n5. Asynchronous Methods for Deep Reinforcement Learning, Volodymyr Mnih, Adrià \\nPuigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, \\nKoray Kavukcuoglu (2016) \\n6. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic \\nActor, Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine. (2018) \\n \\nPapers on RLHF \\n1. Deep reinforcement learning from human preferences, Paul Christiano, Jan Leike, Tom B. Brown, \\nMiljan Martic, Shane Legg, Dario Amodei, NeurIPS (2017) \\n2. Training language models to follow instructions with human feedback, L. Ouyang, J. Wu, X. Jiang, \\nD. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al,  NeurIPS \\n(2022) \\n3. Contextual dueling bandits. Dudik, M., Hofmann, K., Schapire, R. E., Slivkins, A. and Zoghi, M. \\n(2015).  In Conference on Learning Theory. [THEORY] \\n4. Preference-based reinforcement learning with finite-time guarantees. Yichong Xu, Ruosong \\nWang, Lin Yang, Aarti Singh, and Artur Dubrawski. NeurIPS (2020) [THEORY] \\n5. Dueling rl: reinforcement learning with trajectory preferences, A. Pacchiano, A. Saha, and J. Lee.  \\n(2021) [THEORY] \\n6. Principled Reinforcement Learning with Human Feedback from Pairwise or K-wise Comparisons, \\nBanghua Zhu, Michael I. Jordan, Jiantao Jiao, ICML  (2023) [THEORY] \\n7. Nash Learning from Human Feedback,  Munos et al., ICML (2024)  \\n8. Self-Play Preference Optimization for Language Model Alignment, Yue Wu, Zhiqing Sun, Huizhuo \\nYuan, Kaixuan Ji, Yiming Yang, Quanquan Gu, ICML (2024) \\n \\n \\n \\n \\n \\n \\n ']\n",
            "Input: Explore the impact of natural language understanding on chatbot technology advancements.\n",
            "Rewritten Input:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expected Ouput Generation"
      ],
      "metadata": {
        "id": "GwkoDUMa_d8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5. Generate Expected Output\n",
        "...\n",
        "\n",
        "# Define prompt template\n",
        "expected_output_template = f\"\"\"\n",
        "I want you to generate an answer for the given `input`. This answer has to be factually aligned to the provided context.\n",
        "\n",
        "Context: {context}\n",
        "Input: {evolved_query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Fill in the values\n",
        "\n",
        "prompt = expected_output_template.replace(\"{context}\", str(context)).replace(\"{evolved_query}\", evolved_query.content)\n",
        "\n",
        "# Generate expected output\n",
        "expected_output = ChatOpenAI(openai_api_key=OPEN_API_KEY).invoke(prompt)\n"
      ],
      "metadata": {
        "id": "J9WyVzbg7im7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expected_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVS8_AMM_4ZZ",
        "outputId": "3394631e-9349-418f-b443-eff12a2990e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Natural language understanding plays a crucial role in the progress and effectiveness of chatbot technology. By enabling chatbots to comprehend and respond to human language in a more nuanced and contextually appropriate manner, advancements in natural language understanding enhance the user experience by facilitating more engaging and productive interactions. These improvements can lead to more accurate responses, higher customer satisfaction, and increased efficiency in various applications such as customer service, information retrieval, and task automation. As chatbots continue to evolve, the integration of sophisticated natural language understanding capabilities will be key to further enhancing their performance and expanding their potential use cases.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 2409, 'total_tokens': 2526, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9a5c1231-222a-4f93-9f5c-c44a5733c762-0', usage_metadata={'input_tokens': 2409, 'output_tokens': 117, 'total_tokens': 2526, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrap Evolved Query, Context, and Expected Output"
      ],
      "metadata": {
        "id": "CK_4Z2ehAJGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import Optional, List\n",
        "...\n",
        "\n",
        "class SyntheticData(BaseModel):\n",
        "  query: str\n",
        "  expected_output: Optional[str]\n",
        "  context: List[str]\n",
        "\n",
        "  def __init__(self, query, expected_output, context):\n",
        "    super().__init__(\n",
        "      query = query,\n",
        "      expected_output = expected_output,\n",
        "      context = context\n",
        "    )\n",
        "\n",
        "q = evolved_query\n",
        "if type(q) is not str:\n",
        "  q = q.content\n",
        "\n",
        "out = expected_output\n",
        "if type(out) is not str:\n",
        "  out = out.content\n",
        "\n",
        "synthetic_data = SyntheticData(\n",
        "\tquery=q,\n",
        "\texpected_output=out,\n",
        "\tcontext=context\n",
        ")\n",
        "\n",
        "# Simple implementation of synthetic dataset\n",
        "synthetic_dataset = []\n",
        "synthetic_dataset.append(synthetic_data)\n"
      ],
      "metadata": {
        "id": "DchtST5aAAMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepEval"
      ],
      "metadata": {
        "id": "dKwKZ4hmCxtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUfpB1k2AvEh",
        "outputId": "3258f7f3-7180-4aa8-f16a-71241909a24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepeval in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from deepeval) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepeval) (4.67.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from deepeval) (8.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.9.0)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.15.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from deepeval) (13.9.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from deepeval) (5.29.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from deepeval) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.11/dist-packages (from deepeval) (2.20.0)\n",
            "Requirement already satisfied: pytest-repeat in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.9.3)\n",
            "Requirement already satisfied: pytest-xdist in /usr/local/lib/python3.11/dist-packages (from deepeval) (3.6.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from deepeval) (3.1.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.3.16)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.12.15)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.3.33)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.3.3)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.3.16)\n",
            "Requirement already satisfied: docx2txt~=0.8 in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.8)\n",
            "Requirement already satisfied: importlib-metadata>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from deepeval) (8.5.0)\n",
            "Requirement already satisfied: tenacity<=9.0.0 in /usr/local/lib/python3.11/dist-packages (from deepeval) (9.0.0)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from deepeval) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from deepeval) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from deepeval) (1.29.0)\n",
            "Requirement already satisfied: grpcio==1.67.1 in /usr/local/lib/python3.11/dist-packages (from deepeval) (1.67.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from deepeval) (1.6.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from deepeval) (3.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.0.2->deepeval) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.50b0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deepeval) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->deepeval) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->deepeval) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->deepeval) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->deepeval) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->deepeval) (2024.12.14)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->deepeval) (2.0.37)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain->deepeval) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->deepeval) (0.3.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->deepeval) (1.33)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->deepeval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->deepeval) (2.27.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->deepeval) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->deepeval) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->deepeval) (2.7.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->deepeval) (1.59.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->deepeval) (0.8.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.4.3)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.4.0)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.15 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.12.15)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.6.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.3.16)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.4.4)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index->deepeval) (3.9.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->deepeval) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->deepeval) (1.5.0)\n",
            "Requirement already satisfied: execnet>=2.1 in /usr/local/lib/python3.11/dist-packages (from pytest-xdist->deepeval) (2.1.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->deepeval) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->deepeval) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->deepeval) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->deepeval) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->deepeval) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->deepeval) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->deepeval) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->deepeval) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->deepeval) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->deepeval) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->deepeval) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (0.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.17.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (0.23.0)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.15->llama-index->deepeval) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.15->llama-index->deepeval) (1.2.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.15->llama-index->deepeval) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.15->llama-index->deepeval) (11.1.0)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->deepeval) (0.1.11)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (4.12.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (5.2.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval) (0.5.20)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->deepeval) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index->deepeval) (2024.11.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (1.3.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->deepeval) (1.0.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->deepeval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->deepeval) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->deepeval) (2025.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (2.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->deepeval) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->deepeval) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->deepeval) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG30UbvhEUEW",
        "outputId": "a98455fb-2b18-4d41-ff13-8cc693085c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.11.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.67.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.9.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.11.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=e85c8b028fbc7e63e199753de71efe332ddf14d5a006a2ad99bf586e2de1478c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, coloredlogs, build, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, chromadb\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.8 httptools-0.6.4 humanfriendly-10.0 kubernetes-32.0.0 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.11.0 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.45.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "Gx7XoylhENXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepeval.synthesizer import Synthesizer\n",
        "\n",
        "synthesizer = Synthesizer()\n",
        "synthesizer.chunk_size = 200\n",
        "synthesizer.chunk_overlap = 0\n",
        "print(synthesizer.chunk_size)\n",
        "synthesizer.generate_goldens_from_docs(\n",
        "    document_paths=['drive/MyDrive/ToRead/quantum_cir.pdf'],\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9-oJTxqqC1tn",
        "outputId": "0e332154-686a-49fb-c261-46030a825e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✨ 🚀 ✨ Loading Documents: 100%|██████████| 1/1 [00:10<00:00, 10.74s/it]\n",
            "✨ 📚 ✨ Chunking Documents: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
            "✨ 🧩 ✨ Generating Contexts: 100%|██████████| 9/9 [00:06<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Utilizing \u001b[1;36m8\u001b[0m out of \u001b[1;36m75\u001b[0m chunks.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Utilizing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> out of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span> chunks.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✨ Generating up to 6 goldens using DeepEval (using gpt-4o and text-embedding-3-small, method=docs): 100%|██████████| 6/6 [00:36<00:00,  6.11s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Golden(input='Compare the feasibility and challenges of MPS vs. TN simulations in high-fidelity quantum circuits.', actual_output=None, expected_output='Matrix-product-state (MPS) simulations present significant challenges when applied to high-fidelity quantum circuits. This is primarily due to the difficulty in handling the high levels of entanglement found in such systems, as MPS is inherently limited by the bond dimension it can effectively manage. The high-fidelity and connectivity in quantum circuits, such as those involving H2, prove particularly formidable for MPS due to their ability to produce near-maximally entangled states. As a result, current MPS methods face limitations in scalability and fidelity, rendering them impractical for simulating complex quantum circuits at experimental fidelities.\\n\\nIn contrast, tensor-network (TN) methods offer a more general framework that can potentially approximate states with greater bipartite entanglement than MPS can handle. However, these methods are computationally demanding, especially as circuit depth increases and the quantum states approach maximal entanglement. The computational cost, particularly when slicing operations are involved, quickly becomes prohibitive with deeper circuits, even on the most powerful supercomputers. This exponential cost increase, along with the associated fidelity loss from state compression, underscores the challenges TN methods face in achieving the high fidelities seen in state-of-the-art quantum hardware simulations.\\n\\nDespite these barriers, TN methods may offer improved simulations compared to MPS through the use of a broader ansatz that can potentially capture the entanglement complexities better. However, large-scale TN simulations still demand significant computational resources and advancements in algorithm efficiency to become a feasible alternative for truly capturing the essence of high-fidelity quantum circuits. Consequently, while both MPS and TN approaches can offer insights into quantum circuit simulations, their current computational demands and limitations emphasize the difficulty of matching the fidelity of quantum hardware.', context=[' ascribe an error per 2Q gate\\nεMPS via the relation FMPS = (1 − εMPS)(# of 2Q gates) ,\\nwhich can then be compared to the effective error per\\n2Q gate on quantum hardware, ε. Assuming that fidelity\\nis well approximated by FXEB for both the data output\\nby a quantum computer and for this classical simulation\\nmethod [31], quantum advantage in cross-entropy bench-\\nmarking is only possible if feasible classical resources can-\\nnot achieve εMPS <∼ ε. Below we will show that the high\\ngate fidelities and connectivity of H2 make simulations\\nbased on MPS extremely challenging, and likely infeasi-\\nble at the scale and fidelity of the circuits run in this\\nwork. It would be interesting to investigate to what\\nextent approximate simulations could be improved by\\nusing a more general TN ansatz than the MPS consid-\\nered here. However, fast (with circuit depth) suppres-\\nsion of any low-entanglement partitions is guaranteed by\\nthe way we construct our circuits. Ultimately, H2 can\\nproduce states that are near-maximally entangled with\\nrespect to all possible partitions while maintaining high\\nstate fidelities, and sampling from such states should pose\\nsubstantial challenges for existing compression-based TN\\nmethods.\\nAll MPS results reported in this section were obtained\\nwith a density-matrix renormalization group (DMRG)\\nalgorithm similar to that described in Ref. [4]. In par-\\nticular, we approximate the amplitude of a particular\\noutput bit string of a circuit using a closed-simulation\\napproach, e.g. we evolve one MPS forward from the ini-', '32\\nM(7)\\n28\\nM(6)\\n28\\nM(5)\\n28\\nM(4)\\n214\\nM(3)\\n214\\n(a) (b) (c)\\n228\\nM(1) M(2)\\n228 214\\nM(1) M(2)\\n214\\nM(4)\\n28\\nM(3)\\n2828\\nM(1) M(2)\\n28\\nFIG. A23. Graph partitioning for blocked MPS simulations of a depth 5 circuit on 56 qubits. The graph from which the circuit\\nis constructed (shown without edge coloring) is partitioned into b = 2 (a), b = 4 (b), or b = 7 (c) using KaHyPar. The objective\\nis to minimize the number of inter-block edges, which ultimately (upon assigning blocks to MPS tensors) minimizes the number\\nof gates that must be applied between MPS tensors.\\n101 102 103 104 105 106 107 108\\n0.00\\n0.02\\n0.04\\n0.06\\n0.08\\n0.10\\n0.12\\n0.14\\n0.16MPS\\nd = 10, 4x[14]\\nd = 10, 7x[8]\\nd = 10, 14x[4]\\nd = 10, 28x[2]\\nd = 10, 56x[1]\\nd = 20, 4x[14],\\nd = 20, 7x[8],\\nd = 20, 14x[4],\\nd = 20, 28x[2],\\nd = 20, 56x[1],\\nFIG. A24. Error per gate εMPS in DMRG simulations for\\ndepth-10 (blue) and depth-20 (magenta) circuits using a va-\\nriety of blocking strategies. The lines are a linear fit to the\\nlargest two bond dimensions plotted for each blocking strat-\\negy (χ = 64, 128), and provide estimates of the bond dimen-\\nsion required to achieve the experimental error rates (dotted\\nhorizontal line at the bottom of the plot). The stars are lower\\nbounds on the required bond dimension for an optimal bipar-\\ntite MPS extracted from Clifford simulations (see Fig. A26\\nand supporting text).\\nmay well bias the extrapolated bond dimension down rel-\\native to the true requirements.\\nIn Ref. [12], the authors consider the bond dimen-\\nsion requirements to write down a bipartite MPS |ΦMPS⟩\\nthat approximates an arbitrary state |Ψ⟩ with fidelity\\nf = |⟨ΦMPS|Ψ⟩|2. In particular, they show that the fi-\\ndelity is bounded above as f2 ≤ χTr(ρ2), where ρ is the\\nreduced density matrix of the exact state |Ψ⟩ on either\\nside of the bipartition. Since the computation of ampli-\\ntudes by evolving two MPSs toward the middle of the\\ncircuit achieves an effective simulation fidelity F ∼ f2\\n(being diminished by the loss of fidelity of both the for-\\nward and backward evolutions), they conclude that the\\nsimulation fidelity F achievable at fixed bond dimension\\nis bounded above as F ≤ χ Tr(ρ2).\\nDiscrepant accounts of the relationship between the\\nachievable MPS fidelity and the associated FXEB have\\nbeen reported in the literature (see Refs. [4] and [12]),\\nthough we note that the fidelities here are sufficiently\\nlarge that the discrepancies between these two references\\nare relatively inconsequential. We also performed nu-\\nmerical simulations for our circuits in the range of fideli-\\nties relevant to the experiment, and find that F = f2\\nserves as an excellent proxy for the achievable values of\\nFXEB from sampling based on closed-simulation ampli-\\ntude calculations. For these calculations, we consider\\nRG circuits on 24 qubits at depth 10 (at which point\\nthe output distribution of the exact circuits is well con-\\nverged to the Porter-Thomas distribution). We sample\\na random bitstring x, and then evolve |0⟩ (forward) and\\n|x⟩ (backwards) to the midpoint of the circuit. Both\\nstates are then optimally approximated by a bond di-\\nmension χ MPS via direct singular-value decomposition\\n(SVD), and we record both the estimated probability\\nfor bitstring x (squared overlap of the two MPSs) and\\nthe fidelity F = f0fx, where f0(x) is computed from\\nthe discarded weight of', '8\\nas a function of circuit depth, d, averaged over 20 circuit\\ninstances at N = 56. We also show the reference FLOPs\\nof statevector contraction and identify three distinct re-\\ngions. First a ‘shallow’ region where both the cost and\\nwidth increase exponentially but are still far below the\\nstatevector cost and no slicing is needed. Next, an ‘in-\\ntermediate’ regime where even though the slicing reduces\\nW by a factor of up to 2 26 ∼ 64 million, it introduces no\\nsignificant overhead. Finally, a ‘deep’ regime where the\\nunconstrained FLOPs and width converge with statevec-\\ntor, but the cost of the sliced contraction continues to\\ngrow exponentially.\\nAt the intermediate to deep transition point around\\nd = 12, where slicing overhead starts to emerge, the\\nFLOP cost of ∼1020 is already very significant, although\\ncertainly within reach of the largest super-computers\\nwhich can achieve ∼1018 FLOPs per second [28]. How-\\never the median sliced cost continues to exponentially\\ngrow to ∼1030 as the depth increases to d = 20, putting\\nthe computation well out of reach. We note that while\\nimproved techniques (that make use of extensive caching\\nfor example) might bring this cost down somewhat, no\\nsuch method is expected to fully remove the exponential\\ncost of constraining W ≪ 2N for deep circuits.\\nWe also emphasize that these costs are meant primar-\\nily to situate the relative classical hardness of different\\ndepths with respect to other circuits. As discussed in\\nSec. III D, quantum RCS efforts generally produceS sam-\\nples from C different circuits (for a total of M = S × C\\nsamples) such that the expected value of FXEB averaged\\nacross all samples could in principle be distinguished from\\nzero with high statistical confidence (putting aside the\\nquestion of how hard the verification would be). To ac-\\ntually simulate the RCS experiments performed in this\\npaper or to verify FXEB of the samples generated by H2,\\none would want to perform at least S such amplitude\\ncontractions for each of the C circuits. While recent ad-\\nvances have shown that ‘multi-contraction’ for a single\\ncircuit can be performed with cost sublinear in S [22–\\n24], having to draw many samples still presents a sig-\\nnificant computational increase. Moreover, in all RCS\\ndata that we report [29] we use a relatively small num-\\nber of shots per circuit ( S = 20), so the sublinearity of\\nsuch methods provides only a marginal benefit. We also\\nnote that when targeting FXEB < 1 in classical RCS, a\\ngeneric speedup of 1/FXEB is available to brute-force TN\\nmethods [30]. Given the large fidelity values expected\\neven for the deepest circuits implemented in this paper\\n(F ≥ 0.1 at d = 24, see Sec. IV), exploitation of hardware\\nimperfections to perform classical RCS of our circuits at\\nsuitably reduced fidelity appears to offer no significant\\nspeedup.\\nC. The cost of approximate tensor network\\nsimulations\\nOne promising method for approximately simulating\\nquantum circuits is to utilize a tensor-network-based\\nansatz suitable for capturing states with limited bipartite\\nentanglement. At sufficiently early times, when bipartite\\nentanglement is limited, this method can be exact even\\nfor system sizes well beyond the reach of full statevector\\nsimulation. However, as the quantum state progresses\\nthrough the circuit and becomes more entangled, it even-\\ntually needs to be compressed to maintain an ansatz con-\\nstrained by available resources (in both memory and run\\ntime). This compression inevitably causes the state to\\nlose fidelity with respect to the exact state, reminiscent\\nof the way gate errors in a noisy quantum circuit cause\\na state to lose fidelity as the depth of a quantum circuit\\nincreases. The less noisy a quantum computer’s gates\\nare, and the more entanglement-per-gate that computer\\ncan generate, the more difficult it becomes for such meth-\\nods to compete with the physically achieved fidelities for\\nhighly-entangled states.\\nIn Refs. [3, 4], the authors have argued that in the case\\nof a matrix-product-state (MPS) ansatz and a random\\ncircuit, the overall fidelity FMPS of the calculation is well\\napproximated by simply accumulating the loss of fidelity\\nin every compression step, and is therefore readily ac-\\ncessible during the calculation despite the unavailabil-\\nity (in general) of the exact state. From the estimated\\nsimulation fidelity one can'], retrieval_context=None, additional_metadata={'evolutions': ['Comparative'], 'synthetic_input_quality': 0.9}, comments=None, tools_called=None, expected_tools=None, source_file='drive/MyDrive/ToRead/quantum_cir.pdf'),\n",
              " Golden(input='Analyze how TN slicing reduces memory usage in large-scale quantum circuit computations.', actual_output=None, expected_output=\".\\n\\nTN slicing is an effective method to manage memory usage in large-scale quantum circuit computations. In this approach, the primary goal is to break down the computation into manageable tasks, or 'slices,' that can individually fit into a single GPU. This method significantly reduces the memory footprint as each slice demands less memory than handling the entire computation at once, which can be infeasible due to limited resources.\\n\\nWhile utilizing TN slicing reduces memory usage, it is important to note that this method is not without trade-offs. Redundant calculations across different slices can introduce computational overheads. This means that while the memory demand is lessened, the total number of calculations (FLOPs) may increase.\\n\\nMoreover, the efficiency of TN slicing is further enhanced through out optimizations such as hyper-graph partitioning combined with simulated annealing. These techniques help find optimal contraction paths that manage the tensor size within the memory constraints (e.g., width W = 2^30 suitable for GPUs with 40-80 GB).\\n\\nThrough these methods, slicing not only addresses memory constraints but also serves as a robust comparison baseline for various simulation tasks, ensuring efficient and feasible processing of quantum circuits in practical settings.\", context=['\\nTN simulations of random quantum circuits [22–24] have\\nfavored a technique called slicing [25, 26] that instead\\nbreaks the computation into many independent tasks,\\neach able to fit onto a single GPU. It is therefore natural\\nto optimize the FLOP cost of sliced contraction subject\\nto a constraint on the memory footprint of each individ-\\nual slice. The potentially enormous reduction in mem-\\nory footprint is not always free however, and at some\\npoint redundantly repeated operations introduce signif-\\nicant overhead. Below, we will compare the memory-\\nunconstrained and sliced cost for exact computation of\\na single amplitude (‘strong simulation’) of the random\\nquantum circuits considered here, which serves both as a\\nbaseline for various tasks such as sampling and XEB ver-\\nification, and a useful comparison point to other circuits.\\nWe employ hyper-graph partitioning [20, 27] with simu-\\nlated annealing refinement [23] to find highly optimized\\nTN contraction paths, and in the sliced case enforce a\\nmaximum tensor size, or ‘width’ W = 2 30, appropri-\\nate for the current generation of GPUs with 40-80GB\\nof memory.\\nIn Fig. 4(a,b) we plot the contraction cost in FLOPs\\n(assuming complex tensors) and the contraction width', '7\\nexcept that the gated pairs are drawn as edges of a 2D\\nsquare lattice, as in Fig. 3(b). All gates corresponding\\nto edges of a given color can be applied in a single layer,\\nand for circuits with d > 4 layers we simply proceed\\ncyclically through the color list until the desired depth is\\nreached. To minimize contraction cost fluctuations due\\nto boundary effects, we sample 10 2D grids at each N\\nand d, where each grid is obtained by starting with a\\nnominal square lattice with a vertex centered at the ori-\\ngin, applying a random offset and rotation to the lattice,\\nand then selecting the N vertices with smallest Euclidean\\ndistance from the origin. The 2D circuits are slightly less\\ndensely gated than the RG circuits (which always have\\nexactly N/2 gates per layer) because qubits at the edges\\nof the 2D lattice are not gated in each layer. To make\\na fair comparison between RG and 2D circuits, we asso-\\nciate an effective circuit depth deff = n2Q/(N/2) to each\\ncircuit, with n2Q the number of 2Q gates in the circuit\\n(note that deff = d for the densely-gated RG circuits).\\nComparisons at fixed deff and N then always amount to\\ncomparisons at a fixed total number of 2Q gates. It is\\nalso important to note that for this comparison, we have\\nchosen the Quantinuum native UZZ (π/2) gate as the 2Q\\ngate. It is well known that iSWAP-like gates (gates with\\nmaximum entropy of their singular value decomposition)\\nlead to relatively harder to simulate 2D circuits than\\nUZZ(π/2) when compared at fixed depth; the contrac-\\ntion cost estimates reported here for 2D circuits should\\nnot be conflated with direct cost estimates of circuits run\\nin specific experiments on superconducting qubits, which\\nwill generally be higher for a given ( N, d) given the use\\nof rank-4 entangling gates. Nevertheless, the scaling ar-\\nguments made here apply equally well regardless of the\\n2Q gate choice.\\nAs discussed above, constant complexity density is\\nmaintained by scaling d ∼\\n√\\nN in 2D [see the inset of\\nFig. 3(d)]. In contrast, RG circuits empirically achieve\\nfixed complexity density at constant depth as N → ∞,\\nevidenced by the flat contours in Fig. 3(c). The constant\\nasymptotic complexity density observed in Fig. 3(c) is\\nproven in the appendices, and is a consequence of the gate\\npairs being chosen in correspondence with the edges of\\ngraphs with good asymptotic expansion properties. The\\nwhite-dashed arrows in Fig. 3 correspond to the circuits\\nachievable in the current 56-qubit configuration of H2,\\nand at this system size the depth at whichCd,56 saturates\\nto near unity (i.e. where the contraction cost saturates\\nto the statevector simulation cost of 56 qubits) is roughly\\nhalf as large ( d ≈ 12) for RG circuits as for 2D circuits\\n(d ≈ 22).\\nB. Exact contraction cost with memory constraints\\nOptimization of TN contraction solely targeting FLOP\\nminimization can result in contraction orders that pro-\\nduce large intermediate tensors; the FLOP cost of a TN\\n5\\n10\\n15\\n20\\n25\\n30Cost, log10 [FLOPs]\\nState-vector\\nShallow Intermediate Deep \\n(a)\\nSliced\\nUnconstrained\\n4 6 8 10 12 14 16 18 20\\nDepth, d\\n30\\n56Width, log2 [W]\\n(b)\\nSliced\\nUnconstrained\\nFIG. 4. The impact of constraining memory on cost for TN\\ncontraction of a single amplitude for random quantum circuits\\nwith N = 56. (a) FLOP cost of unconstrained optimized\\ncontraction paths compared with those sliced to W=230 as a\\nfunction of circuit depth,d. The cost of statevector simulation\\nis marked for reference. (b) Size of the largest intermediate\\ntensor, or ‘contraction width’, W, as a function of circuit\\ndepth. The lines represent the median behavior across 20\\ncircuit instances, with the bands showing the min/max range.\\ncontraction is immaterial if those intermediate tensors\\ncannot fit within available memory. While utilizing dis-\\ntributed storage for contractions is a theoretical possibil-\\nity up to a point, in practice, all large scale brute-force', '5\\nWe are generally unaware ofany classical methods to pro-\\nduce FXEB numbers comparable to what we expect from\\nthese circuits without performing essentially exact nu-\\nmerical simulations of the circuit (up to the modest loss\\nin fidelity observed experimentally, see Sec. IV). While\\nthe above statement certainly warrants further scrutiny,\\nwe take this assumption as motivation to focus primarily\\non the difficulty of exact tensor network contraction in\\nthe remainder of this work. However, in Sec. III C we also\\nanalyze the performance of tensor-network-based approx-\\nimate simulation techniques, and show that the random\\ngeometries explored here significantly increase (relative\\nto local geometries) the classical resource requirements\\nto achieve a given quality of approximation.\\nA. Circuit geometry and the cost of exact\\ntensor-network contraction\\nThe most efficient known general-purpose classical\\nmethod to simulate quantum circuits is to represent the\\nprobability of an output bit string as a tensor network\\n(TN) and perform exact contraction of that network. To-\\ngether with rejection sampling or other related methods,\\nsuch calculations enable classical RCS at a cost lower-\\nbounded by the cost of computing one such probability.\\nActually contracting the TN associated to a single prob-\\nability incurs a cost that can be highly dependent on the\\norder in which the contraction of tensors is performed.\\nFor example, while there is always an ordering that leads\\nto a time-like progression of the full statevector, with\\na computational cost that scales as 2 N , circuits of low\\ndepth and/or low-connectivity will generally admit con-\\ntraction orders with much lower cost. Therefore, to as-\\nsign a cost to the contraction of a given TN it is critical\\nto minimize the contraction cost over all possible con-\\ntraction orders. While it may be computationally hard\\nto determine the optimal contraction order in general\\n[19], many good heuristic methods have been developed\\nin recent years. The contraction costs reported in this\\nmanuscript are obtained using cotengra [20], a Python li-\\nbrary that supports a variety of performant heuristic con-\\ntraction order optimizers and hyperparameter optimiza-\\ntion strategies to tune those optimizers. For the results\\ndiscussed in this section contraction order is optimized\\nby targeting the minimization of floating-point opera-\\ntions (FLOPs) assuming no memory constraints. Since\\nwe have not performed exhaustive searches for FLOPs-\\noptimized contraction orderings, all reported costs are,\\nstrictly speaking, only upper bounds on the true contrac-\\ntion cost. However, it is also important to note that the\\nassumption of unconstrained memory can cause one to\\nseriously underestimate the cost of contraction in a more\\nrealistic memory-constrained setting. The deepest 56-\\nqubit circuits run in this paper are likely much harder to\\ncontract in practice than the FLOPs requirements com-\\nputed in this section would suggest. In Sec. III B we in-\\nvestigate the complexity of memory-constrained TN con-\\n|0⟩ |0⟩ |0⟩ |0⟩ |0⟩ |0⟩\\n Haar-random = SU(2)\\nUZZ(π/2) = e−i(π/4)Z⊗Z\\n2 3\\n1 4\\n6 5\\n1 2 3 4 5 6\\n     (random 3-regular graph)  (random depth-3 circuit)Cd,N(a) (b)\\n<latexit sha1_base64=\"J1mR/GoX83xLoqS5Hggrr91ZLmU=\">AAACEHicbVDLSsNAFL3xWesr1aWbYBFcSEnE17LoQldSwT6gDWEynbRDJ5MwM1FKyE+4d6u/4E7c+gf+gZ/hpM1CWw9cOJxzL/fe48eMSmXbX8bC4tLyympprby+sbm1bVZ2WjJKBCZNHLFIdHwkCaOcNBVVjHRiQVDoM9L2R1e5334gQtKI36txTNwQDTgNKEZKS55Z6YVIDTFi6XXmpf2j28wzq3bNnsCaJ05BqlCg4ZnfvX6Ek5BwhRmSsuvYsXJTJBTFjGTlXiJJjPAIDUhXU45C'], retrieval_context=None, additional_metadata={'evolutions': ['In-Breadth'], 'synthetic_input_quality': 0.9}, comments=None, tools_called=None, expected_tools=None, source_file='drive/MyDrive/ToRead/quantum_cir.pdf'),\n",
              " Golden(input='Considering both low and high-depth circuits, how does gate choice influence simulation hardness and contraction strategies, particularly at fixed depth?', actual_output=None, expected_output='In the context of circuit simulation, gate choice plays a nuanced role in determining the simulation hardness and contraction strategies, especially when considering circuits at fixed depth.\\n\\n### Low-Depth Circuits\\n1. **Gate Rank and Decomposition**:  \\n   - In low-depth circuits, the type of 2Q gates used can significantly influence the simulation cost. Gate choice impacts how tensor networks (TN) are contracted.\\n   - Using 2Q gates with low-rank decompositions, such as rank-2 gates, allows for more efficient contraction strategies. This reduces the computation cost when decomposing and contracting the network.\\n   - For example, using the UZZ(π/2) gate (rank-2) helps achieve reduced contraction costs compared to using rank-4 gates like the iSWAP.\\n\\n### High-Depth Circuits\\n1. **Simulation Hardness and Time-like Contraction**:\\n   - At high circuit depths, the contraction strategy becomes more time-oriented. At this stage, gate choice becomes less critical to the overall contraction cost, as the task approaches the complexity of statevector simulation.\\n   - This is because optimal contraction paths tend to align with the natural \"time-like\" progression of the circuit, minimizing variations caused by specific gate properties.\\n\\n### General Insights at Fixed Depth\\n- When comparing circuits at a **fixed depth**, rank-4 gates may lead to higher contraction costs and are generally more complex to simulate. However, they require careful consideration of fidelity and practical implementation constraints.\\n- However, there is an effective trade-off between using high-complexity gates with higher fidelity and simpler native gates with lower ranks, such as the UZZ (π/2). This trade-off is due to the advantage provided by reduced depth with high-rank gates possibly being counterbalanced by increased complexity and reduced fidelity.\\n- In specific configurations, particularly in more complex geometries or 2D circuits, iSWAP-type gates are known to increase simulation difficulty unless offset by strategic decomposition (e.g., factoring out the SWAP gate).\\n\\nIn conclusion, while high-rank gates may increase computational hardness due to a higher depth, carefully selecting and decomposing gates can optimize contraction strategies and manage simulation costs at fixed depths.', context=['29\\nA7. IMPACT OF GATE CHOICE ON\\nSIMULATION HARDNESS\\nAt sufficiently high depths, optimal TN contraction is\\nexpected to proceed in a time-like direction, exhibiting\\ncomputational costs approaching statevector simulation.\\nIn this limit, gate choice will have minimal impact on\\nthe cost of exact contraction. On the other hand, at\\nlow depths the optimal contraction strategy will generally\\nnot be time-like, in which case it may benefit greatly\\nfrom 2Q gates having low-rank decompositions. A simple\\nexample is the 1D circuit shown in Fig. A20(a), which\\nalways admits the sideways contraction ordering shown\\nin panel (c) with cost 2d. Decomposing the 2Q gates with\\nSchmidt rank rs enables a sideways contraction ordering\\nwith cost ∼ rd/2\\ns . For 2Q gates with rs = 4, such as the\\niSWAP gate, rd/2\\ns = 2d and the contraction cost is the\\nsame for subfigures (c) and (d). For 2Q gates withrs = 2,\\nsuch as the UZZ(π/2) gate, rd/2\\ns = 2 d/2. Therefore, in\\nthis simple 1D example, using a rank-4 entangling gate\\nrather than a rank-2 entangling gate effectively doubles\\nthe circuit depth.\\nThe situation for circuits with more complicated ge-\\nometries is less clear, and we have resorted to numerically\\nstudying the contraction cost dependence on gate rank by\\nusing the heuristic contraction cost optimizers provided\\nby cotengra. Figure A21 compares the exact contraction\\ncost of RG quantum circuits built of 2Q gates having\\nrank-2 (circles) and rank-4 (squares) decompositions. A\\nnatural choice of rank-4 gate would be the iSWAP gate,\\nas it has a uniform (rank-4) Schmidt spectrum and there-\\nfore resists approximation strategies based on low-rank\\ngate approximations. However, the iSWAP gate can be\\nmade rank-2 by factoring out a SWAP gate. Factoring\\nSWAP out of every 2Q gate would effectively map the\\noriginal circuit on one random geometry and with rank-4\\ngates onto a new circuit on a different but still random\\ngeometry with rank-2 gates, and this new circuit should\\nhave a similar exact contraction cost as the original cir-\\ncuit with rank-2 gates. To avoid this simplification strat-\\negy we must use a rank-4 gate that remains rank-4 under\\nSWAP factorization, and we choose a partial iSWAP for\\nthe numerical study in Fig. A21. This choice is essentially\\narbitrary: In the space of all possible 2Q gates, all but\\na set of measure zero has the aforementioned property\\n(being rank-4 and remaining rank-4 under SWAP factor-\\nization), and so nearly any 2Q gate would lead to the\\nsame exact contraction costs given by the black squares\\nin Fig. A21.\\nFrom Fig. A21 we see that, all else being equal, rank-\\n4 gates should be preferred as they lead to higher con-\\ntraction costs at fixed circuit depth. But all else is not\\nequal; Quantinuum’s native UZZ (θ) gate is not rank 4,\\nand building a rank-4 gate requires at least two native\\ngates. In principle, it should be sufficient to append a\\nsingle relatively weak entangler in a different basis to our\\nnative gate (e.g., UZZ (θ) → UZZ (θ)UXX (δ)). However,\\neven in the limit δ → 0 our partial entangler has a non-\\nzero average infidelity of ϵ0 ∼ 4.6(6) × 10−4 [6]. Thus,\\none can always achieve the same circuit fidelity using\\njust the native 2Q gate at a depth increased by a factor\\nof r ≡ [ε2Q + (5/4)ϵ0]/ε2Q. Rescaling the depths of the\\nrank-4 (black) curve in Fig. A21 by a factor of r yields\\na result very similar to the rank-2 curve, suggesting that\\nthe advantage (in depth reduction at fixed contraction\\ncost) of using a rank-4 gate is largely offset by the dis-\\nadvantage (in achievable depth at fixed fidelity) due to\\nthe relatively lower rank-4 gate fidelity. Therefore, we\\nhave opted to take the simpler route of applying a single\\nUZZ (π/2) to each qubit pair gated in each layer of our\\ncircuits (as described in Appendix A4).\\nA8.', '7\\nexcept that the gated pairs are drawn as edges of a 2D\\nsquare lattice, as in Fig. 3(b). All gates corresponding\\nto edges of a given color can be applied in a single layer,\\nand for circuits with d > 4 layers we simply proceed\\ncyclically through the color list until the desired depth is\\nreached. To minimize contraction cost fluctuations due\\nto boundary effects, we sample 10 2D grids at each N\\nand d, where each grid is obtained by starting with a\\nnominal square lattice with a vertex centered at the ori-\\ngin, applying a random offset and rotation to the lattice,\\nand then selecting the N vertices with smallest Euclidean\\ndistance from the origin. The 2D circuits are slightly less\\ndensely gated than the RG circuits (which always have\\nexactly N/2 gates per layer) because qubits at the edges\\nof the 2D lattice are not gated in each layer. To make\\na fair comparison between RG and 2D circuits, we asso-\\nciate an effective circuit depth deff = n2Q/(N/2) to each\\ncircuit, with n2Q the number of 2Q gates in the circuit\\n(note that deff = d for the densely-gated RG circuits).\\nComparisons at fixed deff and N then always amount to\\ncomparisons at a fixed total number of 2Q gates. It is\\nalso important to note that for this comparison, we have\\nchosen the Quantinuum native UZZ (π/2) gate as the 2Q\\ngate. It is well known that iSWAP-like gates (gates with\\nmaximum entropy of their singular value decomposition)\\nlead to relatively harder to simulate 2D circuits than\\nUZZ(π/2) when compared at fixed depth; the contrac-\\ntion cost estimates reported here for 2D circuits should\\nnot be conflated with direct cost estimates of circuits run\\nin specific experiments on superconducting qubits, which\\nwill generally be higher for a given ( N, d) given the use\\nof rank-4 entangling gates. Nevertheless, the scaling ar-\\nguments made here apply equally well regardless of the\\n2Q gate choice.\\nAs discussed above, constant complexity density is\\nmaintained by scaling d ∼\\n√\\nN in 2D [see the inset of\\nFig. 3(d)]. In contrast, RG circuits empirically achieve\\nfixed complexity density at constant depth as N → ∞,\\nevidenced by the flat contours in Fig. 3(c). The constant\\nasymptotic complexity density observed in Fig. 3(c) is\\nproven in the appendices, and is a consequence of the gate\\npairs being chosen in correspondence with the edges of\\ngraphs with good asymptotic expansion properties. The\\nwhite-dashed arrows in Fig. 3 correspond to the circuits\\nachievable in the current 56-qubit configuration of H2,\\nand at this system size the depth at whichCd,56 saturates\\nto near unity (i.e. where the contraction cost saturates\\nto the statevector simulation cost of 56 qubits) is roughly\\nhalf as large ( d ≈ 12) for RG circuits as for 2D circuits\\n(d ≈ 22).\\nB. Exact contraction cost with memory constraints\\nOptimization of TN contraction solely targeting FLOP\\nminimization can result in contraction orders that pro-\\nduce large intermediate tensors; the FLOP cost of a TN\\n5\\n10\\n15\\n20\\n25\\n30Cost, log10 [FLOPs]\\nState-vector\\nShallow Intermediate Deep \\n(a)\\nSliced\\nUnconstrained\\n4 6 8 10 12 14 16 18 20\\nDepth, d\\n30\\n56Width, log2 [W]\\n(b)\\nSliced\\nUnconstrained\\nFIG. 4. The impact of constraining memory on cost for TN\\ncontraction of a single amplitude for random quantum circuits\\nwith N = 56. (a) FLOP cost of unconstrained optimized\\ncontraction paths compared with those sliced to W=230 as a\\nfunction of circuit depth,d. The cost of statevector simulation\\nis marked for reference. (b) Size of the largest intermediate\\ntensor, or ‘contraction width’, W, as a function of circuit\\ndepth. The lines represent the median behavior across 20\\ncircuit instances, with the bands showing the min/max range.\\ncontraction is immaterial if those intermediate tensors\\ncannot fit within available memory. While utilizing dis-\\ntributed storage for contractions is a theoretical possibil-\\nity up to a point, in practice, all large scale brute-force', 'It10cnpmHWilbwWR0MWVNVF/T6QolHIc+rozP1TOern4r5crQgZyZr8KLtyU8jhRhOPp+iBhloqsPB2rTwXBio01QVhQ/YGFh0ggrHSGZR2NMxvEPGkd15yz2undSbV+WYRUgj3Yh0Nw4BzqcAMNaAKGR3iGF3g1now34934mLYuGMXMLvyB8fkDkqadbA==</latexit>\\nG d,N\\nFIG. 2. The circuits considered in this paper have geometries\\ninduced by random regular graphs. For a depth- d circuit on\\nN qubits, denoted Cd,N, we sample a random d-regular graph\\non N nodes, denoted Gd,N (the example shown above is for a\\ndepth-3 circuit on 6 qubits). To arrive at a circuit we associate\\neach vertex of G with a qubit in C, and then assign G an edge-\\ncoloring. Each color is associated with a layer of 2Q gates in\\nC, with each edge of that color corresponding to a 2Q gate\\nin that layer. Adjacent 2Q layers are separated by a layer\\nof Haar-random 1Q gates on each qubit (with a single layer\\nof 1Q gates immediately after state preparation and another\\nimmediately before measurement).\\ntraction for our circuits in more detail, and show that it\\ncontinues to grow extremely quickly with depth after the\\nmeasure of complexity [see Eq. (6)] plotted in Fig. 3(c)\\nsaturates.\\nA convenient way to parameterize the contraction cost\\nof the TN corresponding to a quantum circuit is to take\\nthe base-2 logarithm of the required FLOPs per gate for\\nperforming the contraction [21],\\nNd,N = log2\\n\\x12cost in FLOPs\\nNd/2\\n\\x13\\n. (4)\\nBecause the cost per gate (in FLOPs) of brute-force stat-\\nevector simulation of N qubits scales as 2 N , N can be\\ninterpreted as an effective qubit number in the following\\nsense: A depth d circuit C with cost Nd,N may act on\\nN >Nd,N qubits, but it is only (roughly) as difficult to\\nsimulate as the worst-case hardness of simulating Nd,N\\nqubits. At any fixed depth d, a circuit that is spatially\\nlocal in D-dimensions should have an effective qubit num-\\nber scaling (asymptotically as N → ∞) as the area of a\\nminimal bisecting surface,\\nNd,N ∼ d × N(D−1)/D. (5)\\nThis result is perhaps most recognizable in dimensions\\nD = 1, 2, with the implication that the simulation cost\\nof finite depth circuits is asymptotically independent of\\nN for 1D circuits, and exponential in\\n√\\nN for 2D circuits.\\nIt is also convenient to define a normalized effective qubit\\nnumber\\nCd,N ≡ Nd,N /N ∼ d\\nN1/D , (6)'], retrieval_context=None, additional_metadata={'evolutions': ['Constrained'], 'synthetic_input_quality': 0.6}, comments=None, tools_called=None, expected_tools=None, source_file='drive/MyDrive/ToRead/quantum_cir.pdf'),\n",
              " Golden(input='How do iSWAP-like gates present heightened simulation challenges in 2D circuits compared to UZZ(π/2) gates, particularly when evaluating relative contraction costs across system sizes?', actual_output=None, expected_output='iSWAP-like gates introduce heightened simulation challenges in 2D circuits compared to UZZ(π/2) gates due to their high entropy in singular value decomposition, which leads to increased complexity in simulating quantum entanglement. This greater quantum complexity translates to higher computational difficulty when performing tensor network contractions. The increased contraction costs arise because iSWAP-like gates demand more resources, driving higher FLOP cost and memory requirements. Evaluating relative contraction costs across system sizes becomes challenging as these gates lead to higher computational scaling, evidenced by the consistent increase in required resources as circuit depth or qubit numbers increase.', context=['\\nTN simulations of random quantum circuits [22–24] have\\nfavored a technique called slicing [25, 26] that instead\\nbreaks the computation into many independent tasks,\\neach able to fit onto a single GPU. It is therefore natural\\nto optimize the FLOP cost of sliced contraction subject\\nto a constraint on the memory footprint of each individ-\\nual slice. The potentially enormous reduction in mem-\\nory footprint is not always free however, and at some\\npoint redundantly repeated operations introduce signif-\\nicant overhead. Below, we will compare the memory-\\nunconstrained and sliced cost for exact computation of\\na single amplitude (‘strong simulation’) of the random\\nquantum circuits considered here, which serves both as a\\nbaseline for various tasks such as sampling and XEB ver-\\nification, and a useful comparison point to other circuits.\\nWe employ hyper-graph partitioning [20, 27] with simu-\\nlated annealing refinement [23] to find highly optimized\\nTN contraction paths, and in the sliced case enforce a\\nmaximum tensor size, or ‘width’ W = 2 30, appropri-\\nate for the current generation of GPUs with 40-80GB\\nof memory.\\nIn Fig. 4(a,b) we plot the contraction cost in FLOPs\\n(assuming complex tensors) and the contraction width', '7\\nexcept that the gated pairs are drawn as edges of a 2D\\nsquare lattice, as in Fig. 3(b). All gates corresponding\\nto edges of a given color can be applied in a single layer,\\nand for circuits with d > 4 layers we simply proceed\\ncyclically through the color list until the desired depth is\\nreached. To minimize contraction cost fluctuations due\\nto boundary effects, we sample 10 2D grids at each N\\nand d, where each grid is obtained by starting with a\\nnominal square lattice with a vertex centered at the ori-\\ngin, applying a random offset and rotation to the lattice,\\nand then selecting the N vertices with smallest Euclidean\\ndistance from the origin. The 2D circuits are slightly less\\ndensely gated than the RG circuits (which always have\\nexactly N/2 gates per layer) because qubits at the edges\\nof the 2D lattice are not gated in each layer. To make\\na fair comparison between RG and 2D circuits, we asso-\\nciate an effective circuit depth deff = n2Q/(N/2) to each\\ncircuit, with n2Q the number of 2Q gates in the circuit\\n(note that deff = d for the densely-gated RG circuits).\\nComparisons at fixed deff and N then always amount to\\ncomparisons at a fixed total number of 2Q gates. It is\\nalso important to note that for this comparison, we have\\nchosen the Quantinuum native UZZ (π/2) gate as the 2Q\\ngate. It is well known that iSWAP-like gates (gates with\\nmaximum entropy of their singular value decomposition)\\nlead to relatively harder to simulate 2D circuits than\\nUZZ(π/2) when compared at fixed depth; the contrac-\\ntion cost estimates reported here for 2D circuits should\\nnot be conflated with direct cost estimates of circuits run\\nin specific experiments on superconducting qubits, which\\nwill generally be higher for a given ( N, d) given the use\\nof rank-4 entangling gates. Nevertheless, the scaling ar-\\nguments made here apply equally well regardless of the\\n2Q gate choice.\\nAs discussed above, constant complexity density is\\nmaintained by scaling d ∼\\n√\\nN in 2D [see the inset of\\nFig. 3(d)]. In contrast, RG circuits empirically achieve\\nfixed complexity density at constant depth as N → ∞,\\nevidenced by the flat contours in Fig. 3(c). The constant\\nasymptotic complexity density observed in Fig. 3(c) is\\nproven in the appendices, and is a consequence of the gate\\npairs being chosen in correspondence with the edges of\\ngraphs with good asymptotic expansion properties. The\\nwhite-dashed arrows in Fig. 3 correspond to the circuits\\nachievable in the current 56-qubit configuration of H2,\\nand at this system size the depth at whichCd,56 saturates\\nto near unity (i.e. where the contraction cost saturates\\nto the statevector simulation cost of 56 qubits) is roughly\\nhalf as large ( d ≈ 12) for RG circuits as for 2D circuits\\n(d ≈ 22).\\nB. Exact contraction cost with memory constraints\\nOptimization of TN contraction solely targeting FLOP\\nminimization can result in contraction orders that pro-\\nduce large intermediate tensors; the FLOP cost of a TN\\n5\\n10\\n15\\n20\\n25\\n30Cost, log10 [FLOPs]\\nState-vector\\nShallow Intermediate Deep \\n(a)\\nSliced\\nUnconstrained\\n4 6 8 10 12 14 16 18 20\\nDepth, d\\n30\\n56Width, log2 [W]\\n(b)\\nSliced\\nUnconstrained\\nFIG. 4. The impact of constraining memory on cost for TN\\ncontraction of a single amplitude for random quantum circuits\\nwith N = 56. (a) FLOP cost of unconstrained optimized\\ncontraction paths compared with those sliced to W=230 as a\\nfunction of circuit depth,d. The cost of statevector simulation\\nis marked for reference. (b) Size of the largest intermediate\\ntensor, or ‘contraction width’, W, as a function of circuit\\ndepth. The lines represent the median behavior across 20\\ncircuit instances, with the bands showing the min/max range.\\ncontraction is immaterial if those intermediate tensors\\ncannot fit within available memory. While utilizing dis-\\ntributed storage for contractions is a theoretical possibil-\\nity up to a point, in practice, all large scale brute-force', '5\\nWe are generally unaware ofany classical methods to pro-\\nduce FXEB numbers comparable to what we expect from\\nthese circuits without performing essentially exact nu-\\nmerical simulations of the circuit (up to the modest loss\\nin fidelity observed experimentally, see Sec. IV). While\\nthe above statement certainly warrants further scrutiny,\\nwe take this assumption as motivation to focus primarily\\non the difficulty of exact tensor network contraction in\\nthe remainder of this work. However, in Sec. III C we also\\nanalyze the performance of tensor-network-based approx-\\nimate simulation techniques, and show that the random\\ngeometries explored here significantly increase (relative\\nto local geometries) the classical resource requirements\\nto achieve a given quality of approximation.\\nA. Circuit geometry and the cost of exact\\ntensor-network contraction\\nThe most efficient known general-purpose classical\\nmethod to simulate quantum circuits is to represent the\\nprobability of an output bit string as a tensor network\\n(TN) and perform exact contraction of that network. To-\\ngether with rejection sampling or other related methods,\\nsuch calculations enable classical RCS at a cost lower-\\nbounded by the cost of computing one such probability.\\nActually contracting the TN associated to a single prob-\\nability incurs a cost that can be highly dependent on the\\norder in which the contraction of tensors is performed.\\nFor example, while there is always an ordering that leads\\nto a time-like progression of the full statevector, with\\na computational cost that scales as 2 N , circuits of low\\ndepth and/or low-connectivity will generally admit con-\\ntraction orders with much lower cost. Therefore, to as-\\nsign a cost to the contraction of a given TN it is critical\\nto minimize the contraction cost over all possible con-\\ntraction orders. While it may be computationally hard\\nto determine the optimal contraction order in general\\n[19], many good heuristic methods have been developed\\nin recent years. The contraction costs reported in this\\nmanuscript are obtained using cotengra [20], a Python li-\\nbrary that supports a variety of performant heuristic con-\\ntraction order optimizers and hyperparameter optimiza-\\ntion strategies to tune those optimizers. For the results\\ndiscussed in this section contraction order is optimized\\nby targeting the minimization of floating-point opera-\\ntions (FLOPs) assuming no memory constraints. Since\\nwe have not performed exhaustive searches for FLOPs-\\noptimized contraction orderings, all reported costs are,\\nstrictly speaking, only upper bounds on the true contrac-\\ntion cost. However, it is also important to note that the\\nassumption of unconstrained memory can cause one to\\nseriously underestimate the cost of contraction in a more\\nrealistic memory-constrained setting. The deepest 56-\\nqubit circuits run in this paper are likely much harder to\\ncontract in practice than the FLOPs requirements com-\\nputed in this section would suggest. In Sec. III B we in-\\nvestigate the complexity of memory-constrained TN con-\\n|0⟩ |0⟩ |0⟩ |0⟩ |0⟩ |0⟩\\n Haar-random = SU(2)\\nUZZ(π/2) = e−i(π/4)Z⊗Z\\n2 3\\n1 4\\n6 5\\n1 2 3 4 5 6\\n     (random 3-regular graph)  (random depth-3 circuit)Cd,N(a) (b)\\n<latexit sha1_base64=\"J1mR/GoX83xLoqS5Hggrr91ZLmU=\">AAACEHicbVDLSsNAFL3xWesr1aWbYBFcSEnE17LoQldSwT6gDWEynbRDJ5MwM1FKyE+4d6u/4E7c+gf+gZ/hpM1CWw9cOJxzL/fe48eMSmXbX8bC4tLyympprby+sbm1bVZ2WjJKBCZNHLFIdHwkCaOcNBVVjHRiQVDoM9L2R1e5334gQtKI36txTNwQDTgNKEZKS55Z6YVIDTFi6XXmpf2j28wzq3bNnsCaJ05BqlCg4ZnfvX6Ek5BwhRmSsuvYsXJTJBTFjGTlXiJJjPAIDUhXU45C'], retrieval_context=None, additional_metadata={'evolutions': ['Constrained'], 'synthetic_input_quality': 1.0}, comments=None, tools_called=None, expected_tools=None, source_file='drive/MyDrive/ToRead/quantum_cir.pdf'),\n",
              " Golden(input='How do tensor-network and quantum simulations differ in maintaining fidelity for highly-entangled states?', actual_output=None, expected_output='Tensor-network and quantum simulations maintain fidelity for highly-entangled states differently due to their inherent operational distinctions:\\n\\n1. **Quantum Simulations**:\\n   - **Inherent Fidelity**: Quantum systems naturally maintain high fidelity by utilizing low error rates in hardware, particularly with high-gate fidelities that preserve quantum states efficiently.\\n   - **Entanglement**: These systems can inherently manage and evolve highly-entangled states due to their intrinsic quantum mechanics, allowing them to maintain state fidelities even in complex circuits.\\n\\n2. **Tensor-Network Simulations**:\\n   - **Compression Limitations**: While tensor-network methods, like MPS (Matrix Product States), are suitable for states with limited bipartite entanglement, they struggle to maintain fidelity as entanglement increases. The necessary compression to simulate highly entangled states results in fidelity losses akin to gate errors in quantum circuits.\\n   - **Resource Constraints**: MPS simulations require managing computational resources effectively, which becomes challenging as quantum states become more entangled. This often leads to reduced simulation fidelity due to the constraints on memory and computational power.\\n\\nIn conclusion, while quantum simulations leverage physical properties to maintain fidelity, tensor-network methods encounter significant challenges with resource limitations and compression, which can lead to decreased fidelity with highly-entangled states.', context=[' ascribe an error per 2Q gate\\nεMPS via the relation FMPS = (1 − εMPS)(# of 2Q gates) ,\\nwhich can then be compared to the effective error per\\n2Q gate on quantum hardware, ε. Assuming that fidelity\\nis well approximated by FXEB for both the data output\\nby a quantum computer and for this classical simulation\\nmethod [31], quantum advantage in cross-entropy bench-\\nmarking is only possible if feasible classical resources can-\\nnot achieve εMPS <∼ ε. Below we will show that the high\\ngate fidelities and connectivity of H2 make simulations\\nbased on MPS extremely challenging, and likely infeasi-\\nble at the scale and fidelity of the circuits run in this\\nwork. It would be interesting to investigate to what\\nextent approximate simulations could be improved by\\nusing a more general TN ansatz than the MPS consid-\\nered here. However, fast (with circuit depth) suppres-\\nsion of any low-entanglement partitions is guaranteed by\\nthe way we construct our circuits. Ultimately, H2 can\\nproduce states that are near-maximally entangled with\\nrespect to all possible partitions while maintaining high\\nstate fidelities, and sampling from such states should pose\\nsubstantial challenges for existing compression-based TN\\nmethods.\\nAll MPS results reported in this section were obtained\\nwith a density-matrix renormalization group (DMRG)\\nalgorithm similar to that described in Ref. [4]. In par-\\nticular, we approximate the amplitude of a particular\\noutput bit string of a circuit using a closed-simulation\\napproach, e.g. we evolve one MPS forward from the ini-', '32\\nM(7)\\n28\\nM(6)\\n28\\nM(5)\\n28\\nM(4)\\n214\\nM(3)\\n214\\n(a) (b) (c)\\n228\\nM(1) M(2)\\n228 214\\nM(1) M(2)\\n214\\nM(4)\\n28\\nM(3)\\n2828\\nM(1) M(2)\\n28\\nFIG. A23. Graph partitioning for blocked MPS simulations of a depth 5 circuit on 56 qubits. The graph from which the circuit\\nis constructed (shown without edge coloring) is partitioned into b = 2 (a), b = 4 (b), or b = 7 (c) using KaHyPar. The objective\\nis to minimize the number of inter-block edges, which ultimately (upon assigning blocks to MPS tensors) minimizes the number\\nof gates that must be applied between MPS tensors.\\n101 102 103 104 105 106 107 108\\n0.00\\n0.02\\n0.04\\n0.06\\n0.08\\n0.10\\n0.12\\n0.14\\n0.16MPS\\nd = 10, 4x[14]\\nd = 10, 7x[8]\\nd = 10, 14x[4]\\nd = 10, 28x[2]\\nd = 10, 56x[1]\\nd = 20, 4x[14],\\nd = 20, 7x[8],\\nd = 20, 14x[4],\\nd = 20, 28x[2],\\nd = 20, 56x[1],\\nFIG. A24. Error per gate εMPS in DMRG simulations for\\ndepth-10 (blue) and depth-20 (magenta) circuits using a va-\\nriety of blocking strategies. The lines are a linear fit to the\\nlargest two bond dimensions plotted for each blocking strat-\\negy (χ = 64, 128), and provide estimates of the bond dimen-\\nsion required to achieve the experimental error rates (dotted\\nhorizontal line at the bottom of the plot). The stars are lower\\nbounds on the required bond dimension for an optimal bipar-\\ntite MPS extracted from Clifford simulations (see Fig. A26\\nand supporting text).\\nmay well bias the extrapolated bond dimension down rel-\\native to the true requirements.\\nIn Ref. [12], the authors consider the bond dimen-\\nsion requirements to write down a bipartite MPS |ΦMPS⟩\\nthat approximates an arbitrary state |Ψ⟩ with fidelity\\nf = |⟨ΦMPS|Ψ⟩|2. In particular, they show that the fi-\\ndelity is bounded above as f2 ≤ χTr(ρ2), where ρ is the\\nreduced density matrix of the exact state |Ψ⟩ on either\\nside of the bipartition. Since the computation of ampli-\\ntudes by evolving two MPSs toward the middle of the\\ncircuit achieves an effective simulation fidelity F ∼ f2\\n(being diminished by the loss of fidelity of both the for-\\nward and backward evolutions), they conclude that the\\nsimulation fidelity F achievable at fixed bond dimension\\nis bounded above as F ≤ χ Tr(ρ2).\\nDiscrepant accounts of the relationship between the\\nachievable MPS fidelity and the associated FXEB have\\nbeen reported in the literature (see Refs. [4] and [12]),\\nthough we note that the fidelities here are sufficiently\\nlarge that the discrepancies between these two references\\nare relatively inconsequential. We also performed nu-\\nmerical simulations for our circuits in the range of fideli-\\nties relevant to the experiment, and find that F = f2\\nserves as an excellent proxy for the achievable values of\\nFXEB from sampling based on closed-simulation ampli-\\ntude calculations. For these calculations, we consider\\nRG circuits on 24 qubits at depth 10 (at which point\\nthe output distribution of the exact circuits is well con-\\nverged to the Porter-Thomas distribution). We sample\\na random bitstring x, and then evolve |0⟩ (forward) and\\n|x⟩ (backwards) to the midpoint of the circuit. Both\\nstates are then optimally approximated by a bond di-\\nmension χ MPS via direct singular-value decomposition\\n(SVD), and we record both the estimated probability\\nfor bitstring x (squared overlap of the two MPSs) and\\nthe fidelity F = f0fx, where f0(x) is computed from\\nthe discarded weight of', '8\\nas a function of circuit depth, d, averaged over 20 circuit\\ninstances at N = 56. We also show the reference FLOPs\\nof statevector contraction and identify three distinct re-\\ngions. First a ‘shallow’ region where both the cost and\\nwidth increase exponentially but are still far below the\\nstatevector cost and no slicing is needed. Next, an ‘in-\\ntermediate’ regime where even though the slicing reduces\\nW by a factor of up to 2 26 ∼ 64 million, it introduces no\\nsignificant overhead. Finally, a ‘deep’ regime where the\\nunconstrained FLOPs and width converge with statevec-\\ntor, but the cost of the sliced contraction continues to\\ngrow exponentially.\\nAt the intermediate to deep transition point around\\nd = 12, where slicing overhead starts to emerge, the\\nFLOP cost of ∼1020 is already very significant, although\\ncertainly within reach of the largest super-computers\\nwhich can achieve ∼1018 FLOPs per second [28]. How-\\never the median sliced cost continues to exponentially\\ngrow to ∼1030 as the depth increases to d = 20, putting\\nthe computation well out of reach. We note that while\\nimproved techniques (that make use of extensive caching\\nfor example) might bring this cost down somewhat, no\\nsuch method is expected to fully remove the exponential\\ncost of constraining W ≪ 2N for deep circuits.\\nWe also emphasize that these costs are meant primar-\\nily to situate the relative classical hardness of different\\ndepths with respect to other circuits. As discussed in\\nSec. III D, quantum RCS efforts generally produceS sam-\\nples from C different circuits (for a total of M = S × C\\nsamples) such that the expected value of FXEB averaged\\nacross all samples could in principle be distinguished from\\nzero with high statistical confidence (putting aside the\\nquestion of how hard the verification would be). To ac-\\ntually simulate the RCS experiments performed in this\\npaper or to verify FXEB of the samples generated by H2,\\none would want to perform at least S such amplitude\\ncontractions for each of the C circuits. While recent ad-\\nvances have shown that ‘multi-contraction’ for a single\\ncircuit can be performed with cost sublinear in S [22–\\n24], having to draw many samples still presents a sig-\\nnificant computational increase. Moreover, in all RCS\\ndata that we report [29] we use a relatively small num-\\nber of shots per circuit ( S = 20), so the sublinearity of\\nsuch methods provides only a marginal benefit. We also\\nnote that when targeting FXEB < 1 in classical RCS, a\\ngeneric speedup of 1/FXEB is available to brute-force TN\\nmethods [30]. Given the large fidelity values expected\\neven for the deepest circuits implemented in this paper\\n(F ≥ 0.1 at d = 24, see Sec. IV), exploitation of hardware\\nimperfections to perform classical RCS of our circuits at\\nsuitably reduced fidelity appears to offer no significant\\nspeedup.\\nC. The cost of approximate tensor network\\nsimulations\\nOne promising method for approximately simulating\\nquantum circuits is to utilize a tensor-network-based\\nansatz suitable for capturing states with limited bipartite\\nentanglement. At sufficiently early times, when bipartite\\nentanglement is limited, this method can be exact even\\nfor system sizes well beyond the reach of full statevector\\nsimulation. However, as the quantum state progresses\\nthrough the circuit and becomes more entangled, it even-\\ntually needs to be compressed to maintain an ansatz con-\\nstrained by available resources (in both memory and run\\ntime). This compression inevitably causes the state to\\nlose fidelity with respect to the exact state, reminiscent\\nof the way gate errors in a noisy quantum circuit cause\\na state to lose fidelity as the depth of a quantum circuit\\nincreases. The less noisy a quantum computer’s gates\\nare, and the more entanglement-per-gate that computer\\ncan generate, the more difficult it becomes for such meth-\\nods to compete with the physically achieved fidelities for\\nhighly-entangled states.\\nIn Refs. [3, 4], the authors have argued that in the case\\nof a matrix-product-state (MPS) ansatz and a random\\ncircuit, the overall fidelity FMPS of the calculation is well\\napproximated by simply accumulating the loss of fidelity\\nin every compression step, and is therefore readily ac-\\ncessible during the calculation despite the unavailabil-\\nity (in general) of the exact state. From the estimated\\nsimulation fidelity one can'], retrieval_context=None, additional_metadata={'evolutions': ['Comparative'], 'synthetic_input_quality': 1.0}, comments=None, tools_called=None, expected_tools=None, source_file='drive/MyDrive/ToRead/quantum_cir.pdf'),\n",
              " Golden(input='How do tensor network contraction costs fluctuate with gate rank and spatial circuit geometry?', actual_output=None, expected_output='The contract approach to tensor networks reveals interesting patterns regarding the impact of gate rank and spatial circuit geometry on contraction costs:\\n\\n1. **Gate Rank Impact:** \\n   - **Low Depth:** At lower circuit depths, utilizing 2-qubit (2Q) gates with lower Schmidt ranks can significantly minimize contraction costs. For example, rank-2 gates like UZZ(π/2) yield lower costs compared to rank-4 gates such as iSWAP due to their compact decomposition.\\n   - **High Depth:** As circuit depth increases, the influence of gate choice on contraction costs diminishes, aligning more closely with the cost of statevector simulations.\\n\\n2. **Spatial Circuit Geometry:**\\n   - **1D Circuits:** The contraction costs tend to be independent of the total number of qubits, focusing more on depth and ordering (e.g., sideways contraction ordering).\\n   - **2D Circuits:** These circuits are harder to simulate due to higher contraction costs, exacerbated by circuits such as those using iSWAP-like gates with maximum singular value entropy.\\n   - **RG Circuits:** Circuits laid on random graph geometries, optimized numerically, reveal complex cost behaviors dependent on depth and geometry arrangement (fixed complexity density at constant depth as nodes scale).\\n\\nIn essence, efficient tensor network contraction relies on balancing gate rank and geometric configuration to manage increasing depth complexities, with the choice of gates and circuit layout being key determinants of computational difficulty.', context=['29\\nA7. IMPACT OF GATE CHOICE ON\\nSIMULATION HARDNESS\\nAt sufficiently high depths, optimal TN contraction is\\nexpected to proceed in a time-like direction, exhibiting\\ncomputational costs approaching statevector simulation.\\nIn this limit, gate choice will have minimal impact on\\nthe cost of exact contraction. On the other hand, at\\nlow depths the optimal contraction strategy will generally\\nnot be time-like, in which case it may benefit greatly\\nfrom 2Q gates having low-rank decompositions. A simple\\nexample is the 1D circuit shown in Fig. A20(a), which\\nalways admits the sideways contraction ordering shown\\nin panel (c) with cost 2d. Decomposing the 2Q gates with\\nSchmidt rank rs enables a sideways contraction ordering\\nwith cost ∼ rd/2\\ns . For 2Q gates with rs = 4, such as the\\niSWAP gate, rd/2\\ns = 2d and the contraction cost is the\\nsame for subfigures (c) and (d). For 2Q gates withrs = 2,\\nsuch as the UZZ(π/2) gate, rd/2\\ns = 2 d/2. Therefore, in\\nthis simple 1D example, using a rank-4 entangling gate\\nrather than a rank-2 entangling gate effectively doubles\\nthe circuit depth.\\nThe situation for circuits with more complicated ge-\\nometries is less clear, and we have resorted to numerically\\nstudying the contraction cost dependence on gate rank by\\nusing the heuristic contraction cost optimizers provided\\nby cotengra. Figure A21 compares the exact contraction\\ncost of RG quantum circuits built of 2Q gates having\\nrank-2 (circles) and rank-4 (squares) decompositions. A\\nnatural choice of rank-4 gate would be the iSWAP gate,\\nas it has a uniform (rank-4) Schmidt spectrum and there-\\nfore resists approximation strategies based on low-rank\\ngate approximations. However, the iSWAP gate can be\\nmade rank-2 by factoring out a SWAP gate. Factoring\\nSWAP out of every 2Q gate would effectively map the\\noriginal circuit on one random geometry and with rank-4\\ngates onto a new circuit on a different but still random\\ngeometry with rank-2 gates, and this new circuit should\\nhave a similar exact contraction cost as the original cir-\\ncuit with rank-2 gates. To avoid this simplification strat-\\negy we must use a rank-4 gate that remains rank-4 under\\nSWAP factorization, and we choose a partial iSWAP for\\nthe numerical study in Fig. A21. This choice is essentially\\narbitrary: In the space of all possible 2Q gates, all but\\na set of measure zero has the aforementioned property\\n(being rank-4 and remaining rank-4 under SWAP factor-\\nization), and so nearly any 2Q gate would lead to the\\nsame exact contraction costs given by the black squares\\nin Fig. A21.\\nFrom Fig. A21 we see that, all else being equal, rank-\\n4 gates should be preferred as they lead to higher con-\\ntraction costs at fixed circuit depth. But all else is not\\nequal; Quantinuum’s native UZZ (θ) gate is not rank 4,\\nand building a rank-4 gate requires at least two native\\ngates. In principle, it should be sufficient to append a\\nsingle relatively weak entangler in a different basis to our\\nnative gate (e.g., UZZ (θ) → UZZ (θ)UXX (δ)). However,\\neven in the limit δ → 0 our partial entangler has a non-\\nzero average infidelity of ϵ0 ∼ 4.6(6) × 10−4 [6]. Thus,\\none can always achieve the same circuit fidelity using\\njust the native 2Q gate at a depth increased by a factor\\nof r ≡ [ε2Q + (5/4)ϵ0]/ε2Q. Rescaling the depths of the\\nrank-4 (black) curve in Fig. A21 by a factor of r yields\\na result very similar to the rank-2 curve, suggesting that\\nthe advantage (in depth reduction at fixed contraction\\ncost) of using a rank-4 gate is largely offset by the dis-\\nadvantage (in achievable depth at fixed fidelity) due to\\nthe relatively lower rank-4 gate fidelity. Therefore, we\\nhave opted to take the simpler route of applying a single\\nUZZ (π/2) to each qubit pair gated in each layer of our\\ncircuits (as described in Appendix A4).\\nA8.', '7\\nexcept that the gated pairs are drawn as edges of a 2D\\nsquare lattice, as in Fig. 3(b). All gates corresponding\\nto edges of a given color can be applied in a single layer,\\nand for circuits with d > 4 layers we simply proceed\\ncyclically through the color list until the desired depth is\\nreached. To minimize contraction cost fluctuations due\\nto boundary effects, we sample 10 2D grids at each N\\nand d, where each grid is obtained by starting with a\\nnominal square lattice with a vertex centered at the ori-\\ngin, applying a random offset and rotation to the lattice,\\nand then selecting the N vertices with smallest Euclidean\\ndistance from the origin. The 2D circuits are slightly less\\ndensely gated than the RG circuits (which always have\\nexactly N/2 gates per layer) because qubits at the edges\\nof the 2D lattice are not gated in each layer. To make\\na fair comparison between RG and 2D circuits, we asso-\\nciate an effective circuit depth deff = n2Q/(N/2) to each\\ncircuit, with n2Q the number of 2Q gates in the circuit\\n(note that deff = d for the densely-gated RG circuits).\\nComparisons at fixed deff and N then always amount to\\ncomparisons at a fixed total number of 2Q gates. It is\\nalso important to note that for this comparison, we have\\nchosen the Quantinuum native UZZ (π/2) gate as the 2Q\\ngate. It is well known that iSWAP-like gates (gates with\\nmaximum entropy of their singular value decomposition)\\nlead to relatively harder to simulate 2D circuits than\\nUZZ(π/2) when compared at fixed depth; the contrac-\\ntion cost estimates reported here for 2D circuits should\\nnot be conflated with direct cost estimates of circuits run\\nin specific experiments on superconducting qubits, which\\nwill generally be higher for a given ( N, d) given the use\\nof rank-4 entangling gates. Nevertheless, the scaling ar-\\nguments made here apply equally well regardless of the\\n2Q gate choice.\\nAs discussed above, constant complexity density is\\nmaintained by scaling d ∼\\n√\\nN in 2D [see the inset of\\nFig. 3(d)]. In contrast, RG circuits empirically achieve\\nfixed complexity density at constant depth as N → ∞,\\nevidenced by the flat contours in Fig. 3(c). The constant\\nasymptotic complexity density observed in Fig. 3(c) is\\nproven in the appendices, and is a consequence of the gate\\npairs being chosen in correspondence with the edges of\\ngraphs with good asymptotic expansion properties. The\\nwhite-dashed arrows in Fig. 3 correspond to the circuits\\nachievable in the current 56-qubit configuration of H2,\\nand at this system size the depth at whichCd,56 saturates\\nto near unity (i.e. where the contraction cost saturates\\nto the statevector simulation cost of 56 qubits) is roughly\\nhalf as large ( d ≈ 12) for RG circuits as for 2D circuits\\n(d ≈ 22).\\nB. Exact contraction cost with memory constraints\\nOptimization of TN contraction solely targeting FLOP\\nminimization can result in contraction orders that pro-\\nduce large intermediate tensors; the FLOP cost of a TN\\n5\\n10\\n15\\n20\\n25\\n30Cost, log10 [FLOPs]\\nState-vector\\nShallow Intermediate Deep \\n(a)\\nSliced\\nUnconstrained\\n4 6 8 10 12 14 16 18 20\\nDepth, d\\n30\\n56Width, log2 [W]\\n(b)\\nSliced\\nUnconstrained\\nFIG. 4. The impact of constraining memory on cost for TN\\ncontraction of a single amplitude for random quantum circuits\\nwith N = 56. (a) FLOP cost of unconstrained optimized\\ncontraction paths compared with those sliced to W=230 as a\\nfunction of circuit depth,d. The cost of statevector simulation\\nis marked for reference. (b) Size of the largest intermediate\\ntensor, or ‘contraction width’, W, as a function of circuit\\ndepth. The lines represent the median behavior across 20\\ncircuit instances, with the bands showing the min/max range.\\ncontraction is immaterial if those intermediate tensors\\ncannot fit within available memory. While utilizing dis-\\ntributed storage for contractions is a theoretical possibil-\\nity up to a point, in practice, all large scale brute-force', 'It10cnpmHWilbwWR0MWVNVF/T6QolHIc+rozP1TOern4r5crQgZyZr8KLtyU8jhRhOPp+iBhloqsPB2rTwXBio01QVhQ/YGFh0ggrHSGZR2NMxvEPGkd15yz2undSbV+WYRUgj3Yh0Nw4BzqcAMNaAKGR3iGF3g1now34934mLYuGMXMLvyB8fkDkqadbA==</latexit>\\nG d,N\\nFIG. 2. The circuits considered in this paper have geometries\\ninduced by random regular graphs. For a depth- d circuit on\\nN qubits, denoted Cd,N, we sample a random d-regular graph\\non N nodes, denoted Gd,N (the example shown above is for a\\ndepth-3 circuit on 6 qubits). To arrive at a circuit we associate\\neach vertex of G with a qubit in C, and then assign G an edge-\\ncoloring. Each color is associated with a layer of 2Q gates in\\nC, with each edge of that color corresponding to a 2Q gate\\nin that layer. Adjacent 2Q layers are separated by a layer\\nof Haar-random 1Q gates on each qubit (with a single layer\\nof 1Q gates immediately after state preparation and another\\nimmediately before measurement).\\ntraction for our circuits in more detail, and show that it\\ncontinues to grow extremely quickly with depth after the\\nmeasure of complexity [see Eq. (6)] plotted in Fig. 3(c)\\nsaturates.\\nA convenient way to parameterize the contraction cost\\nof the TN corresponding to a quantum circuit is to take\\nthe base-2 logarithm of the required FLOPs per gate for\\nperforming the contraction [21],\\nNd,N = log2\\n\\x12cost in FLOPs\\nNd/2\\n\\x13\\n. (4)\\nBecause the cost per gate (in FLOPs) of brute-force stat-\\nevector simulation of N qubits scales as 2 N , N can be\\ninterpreted as an effective qubit number in the following\\nsense: A depth d circuit C with cost Nd,N may act on\\nN >Nd,N qubits, but it is only (roughly) as difficult to\\nsimulate as the worst-case hardness of simulating Nd,N\\nqubits. At any fixed depth d, a circuit that is spatially\\nlocal in D-dimensions should have an effective qubit num-\\nber scaling (asymptotically as N → ∞) as the area of a\\nminimal bisecting surface,\\nNd,N ∼ d × N(D−1)/D. (5)\\nThis result is perhaps most recognizable in dimensions\\nD = 1, 2, with the implication that the simulation cost\\nof finite depth circuits is asymptotically independent of\\nN for 1D circuits, and exponential in\\n√\\nN for 2D circuits.\\nIt is also convenient to define a normalized effective qubit\\nnumber\\nCd,N ≡ Nd,N /N ∼ d\\nN1/D , (6)'], retrieval_context=None, additional_metadata={'evolutions': ['Concretizing'], 'synthetic_input_quality': 0.9}, comments=None, tools_called=None, expected_tools=None, source_file='drive/MyDrive/ToRead/quantum_cir.pdf')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}